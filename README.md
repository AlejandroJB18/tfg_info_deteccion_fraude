# tfg_info_deteccion_fraude
Desarrollar un sistema de Machine Learning que no solo clasifique transacciones como fraudulentas o leg√≠timas, sino que **minimice la p√©rdida financiera total esperada**. El modelo debe aprender que un fraude de $10,000 es significativamente m√°s costoso que 10 fraudes de $100.

### Enfoque T√©cnico
* **Problema Imbalanceado:** Tratamiento de la baja tasa de fraude (clase minoritaria).
* **Sensibilidad al Coste:** Incorporaci√≥n del campo `Amount` (monto) como factor de penalizaci√≥n durante el entrenamiento y la evaluaci√≥n.
* **M√©trica Clave:** **Costo Financiero Esperado** (Expected Financial Cost), en lugar de F1-Score o Accuracy.

---

## üìÇ Estructura y C√≥digo

El flujo de trabajo es **secuencial** y est√° dise√±ado para una ejecuci√≥n limpia y legible, adecuada para entornos de desarrollo y depuraci√≥n como **Spyder**.

```plaintext
/data/          ‚Üí Datasets (creditcard.csv, etc.)
/src/           ‚Üí M√≥dulos Python
    ‚îú‚îÄ‚îÄ load_data.py
    ‚îú‚îÄ‚îÄ train_model.py
    ‚îú‚îÄ‚îÄ evaluate.py
    ‚îî‚îÄ‚îÄ compare_models.py
/notebooks/     ‚Üí An√°lisis exploratorio (opcional)
/results/       ‚Üí Modelos, m√©tricas y gr√°ficos
```
### Ejemplos de c√≥digo

```python
# Cargar datos
from src.load_data import load_fraud_csv
df, X, y = load_fraud_csv('data/creditcard.csv')
amount = X['Amount']
```
```python
# Entrenar modelo sensible al coste
from src.train_model import train_rf_with_cost
rf = train_rf_with_cost(X_train, y_train, amount_train, amount_factor=15)
```
```python
# Evaluar con coste real
from src.evaluate import expected_cost, best_threshold_by_cost
cost = expected_cost(y_test, proba, amount_test)
print(f'Costo esperado: ‚Ç¨{cost:,.2f}')
```

## Modelos Comparados

| Modelo         | Ventajas                                  | Desventajas                              |
|----------------|-------------------------------------------|------------------------------------------|
| **RandomForest** | Interpretable, robusto a outliers         | Menos sensible a pesos complejos         |
| **XGBoost**      | Mejor rendimiento en coste, optimizaci√≥n por gradiente | Menos interpretable, requiere m√°s tuning |

> **Resultado t√≠pico:** XGBoost reduce el coste esperado en **~15-25%** vs. RandomForest.

---

## M√©tricas Clave

- **Expected Financial Cost** = `(FN √ó Amount √ó 0.9) + (FP √ó 5)`
- **AUPRC** (para comparaci√≥n)
- **Mejor umbral** optimizado por coste, no por F1.

---

## Posibles Experimentos a Realizar

1. Variaci√≥n de `amount_factor` (5, 10, 15, 20)  
2. Reequilibrado por SMOTE + peso por monto  
3. Undersampling ponderado  
4. Redes neuronales con *custom loss*

> **Ejemplo de conclusi√≥n:** `XGBoost` + `amount_factor=15` ofrece el mejor balance coste/rendimiento.
## Paquetes Python

```bash
pip install pandas scikit-learn xgboost imbalanced-learn matplotlib seaborn
```
