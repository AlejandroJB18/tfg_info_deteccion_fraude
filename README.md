# tfg_info_deteccion_fraude
Este proyecto de Trabajo de Fin de Grado (TFG) desarrolla un sistema de Machine Learning que no solo clasifica transacciones como fraudulentas o leg√≠timas, sino que **minimiza la p√©rdida financiera total esperada** para una entidad bancaria. El modelo debe aprender que un fraude de 10,000‚Ç¨ es significativamente m√°s costoso que 10 fraudes de 100‚Ç¨.

### Enfoque T√©cnico
* **Problema Imbalanceado:** Tratamiento de la baja tasa de fraude (clase minoritaria).
* **Sensibilidad al Coste:** Incorporaci√≥n del campo `Amount` (monto) como factor de penalizaci√≥n durante el entrenamiento y la evaluaci√≥n.
* **M√©trica Clave:** **Costo Financiero Esperado** (Expected Financial Cost), en lugar de F1-Score o Balance Accuracy.

---

## üìÇ Estructura y C√≥digo

El c√≥digo se dise√±a para una ejecuci√≥n  **secuencial**, adecuada para entornos de desarrollo y depuraci√≥n como **Visual Studio** o **Spyder**. El c√≥digo se ha organizado para separar la l√≥gica reutilizable (`src/`) de los experimentos y an√°lisis finales (`notebooks/`).

```plaintext
/data/                                          ‚Üí Datasets (credit_card.csv, cs_training, etc.)
/exploracion/                                   ‚Üí Notebooks de la fase inicial de investigaci√≥n
    ‚îú‚îÄ‚îÄ modelos_convencionales_german...ipynb      
    ‚îú‚îÄ‚îÄ modelos_convencionales_varios....ipynb     
    ‚îî‚îÄ‚îÄ modelos_avanzados.ipynb      
/notebooks/                                     ‚Üí An√°lisis finales
    ‚îú‚îÄ‚îÄ analisis_financiero.ipynb               # Simulaci√≥n y optimizaci√≥n del modelo
    ‚îú‚îÄ‚îÄ analisis_sensibilidad.ipynb             # An√°lisis de robustez de negocio
    ‚îî‚îÄ‚îÄ analisis_xai.ipynb                      # An√°lisis de la explicabilidad del modelo
/models/                                        ‚Üí Modelos entrenados
/results/                                       ‚Üí Modelos, m√©tricas y gr√°ficos
/src/                                           ‚Üí M√≥dulos Python
    ‚îú‚îÄ‚îÄ load_data.py                            # Carga y limpieza de datos
    ‚îú‚îÄ‚îÄ train_model.py                          # Entrenamiento con coste variable
    ‚îú‚îÄ‚îÄ evaluate.py                             # Funci√≥n de Coste Financiero y Optimizaci√≥n de Umbral
    ‚îú‚îÄ‚îÄ compare_models.py                       # Simulaciones
    ‚îî‚îÄ‚îÄ benchmark_utils.py                      # Funciones de entrenamiento de benchmarks para modelos
README.md                                       ‚Üí Este documento
```
### Ejemplos de c√≥digo

```python
# 1. Cargar datos y separar importes
from src.load_data import load_fraud_csv
df, X, y = load_fraud_csv('data/credit_card.csv')

# 2. Entrenar modelo con penalizaci√≥n variable (Amount * factor)
from src.train_model import train_xgb_with_cost
# amount_factor=20 penaliza 20 veces m√°s los errores en fraudes de alto valor
xgb = train_xgb_with_cost(X_train, y_train, amount_train, amount_factor=20)

# 3. Encontrar el umbral que minimiza el coste real
from src.evaluate import best_threshold_by_cost
# Coste = (FN * 90% del Importe) + (FP * 5‚Ç¨ inspecci√≥n)
best_thr, min_cost = best_threshold_by_cost(y_test, proba, amount_test)
```
Dataset Credit Card Fraud Detection de Kaggle [data/credit_card.csv](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
## Modelos Comparados

| Modelo         | Ventajas                                  | Desventajas                              |
|----------------|-------------------------------------------|------------------------------------------|
| **RandomForest** | Interpretable, robusto a outliers         | Menos sensible a pesos complejos         |
| **XGBoost**      | Mejor rendimiento en coste, optimizaci√≥n por gradiente | Menos interpretable, requiere m√°s tuning |

> **Resultado t√≠pico:** XGBoost reduce el coste esperado en **~15-25%** vs. RandomForest.

---

## M√©tricas Clave

- **Expected Financial Cost** = `(FN √ó Amount √ó 0.9) + (FP √ó 5)`
- **AUPRC** (para comparaci√≥n)
- **Mejor umbral** optimizado por coste, no por F1.

---

## üìà Ejemplo de Resultados del c√≥digo *fraud_detection.py*

```python
from src.compare_models import compare_all_factors
compare_all_factors('data/creditcard.csv')
```
## üìä Resultados Reales (04-Nov-2025)

| amount_factor | Modelo   | Umbral | Coste (‚Ç¨) | AUPRC |
|---------------|----------|--------|-----------|-------|
| 2             | XGBoost  | 0.8217 | 1 704     | 0.8861 |
| 5             | XGBoost  | 0.4951 | 1 683     | 0.8891 |
| 10            | XGBoost  | 0.1783 | 1 737     | 0.8858 |
| **20**        | XGBoost  | 0.7821 | 1 660     | 0.8899 |
| 30            | XGBoost  | 0.8217 | 1 660     | 0.8910 |

El **an√°lisis de sensibilidad** (notebooks/analisis_sensibilidad.ipynb) demostr√≥ que el umbral por defecto (0.5) es incorrecto financieramente. El umbral √≥ptimo depende del coste de inspecci√≥n manual (FP):
- Si inspeccionar cuesta < 3‚Ç¨: El modelo debe ser agresivo (Umbral bajo ~0.40).
- Si inspeccionar cuesta ‚â• 3‚Ç¨: El modelo debe ser conservador (Umbral alto 0.7821).
Dado un coste de inspecci√≥n realista de 5‚Ç¨, la estrategia √≥ptima es conservadora (Umbral 0.78), minimizando las falsas alarmas.

### Figuras generadas autom√°ticamente

| Coste Financiero                     | AUPRC                          |
|--------------------------------------|--------------------------------|
| ![Coste vs factor](results/Figure%202025-11-04%20211504.png) | ![AUPRC vs factor](results/Figure%202025-11-04%20211645.png) |

> **Ganador:** `XGBoost` + `amount_factor=30`  
> **Coste m√≠nimo:** **‚Ç¨1 661**  
> **Ahorro:** 17 % vs RandomForest (‚Ç¨1 997)  
> **Fraude recuperado:** **97.24 %** de $60 127.97

## Paquetes Python

```bash
pip install pandas scikit-learn xgboost imbalanced-learn matplotlib seaborn
```
- Ejecuta notebooks/analisis_financiero.ipynb para descargar los datos y ver la optimizaci√≥n.
- Ejecuta notebooks/analisis_sensibilidad.ipynb para ver los mapas de calor de decisi√≥n y generar el modelo final en models/.

