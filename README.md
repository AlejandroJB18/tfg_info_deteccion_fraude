# tfg_info_deteccion_fraude
Desarrollar un sistema de Machine Learning que no solo clasifique transacciones como fraudulentas o leg√≠timas, sino que **minimice la p√©rdida financiera total esperada**. El modelo debe aprender que un fraude de $10,000 es significativamente m√°s costoso que 10 fraudes de $100.

### Enfoque T√©cnico
* **Problema Imbalanceado:** Tratamiento de la baja tasa de fraude (clase minoritaria).
* **Sensibilidad al Coste:** Incorporaci√≥n del campo `Amount` (monto) como factor de penalizaci√≥n durante el entrenamiento y la evaluaci√≥n.
* **M√©trica Clave:** **Costo Financiero Esperado** (Expected Financial Cost), en lugar de F1-Score o Accuracy.

---

## üìÇ Estructura y C√≥digo

El c√≥digo se dise√±a para una ejecuci√≥n  **secuencial**, adecuada para entornos de desarrollo y depuraci√≥n como **Visual Studio** o **Spyder**.

```plaintext
/data/          ‚Üí Datasets (creditcard.csv, etc.)
/src/           ‚Üí M√≥dulos Python
    ‚îú‚îÄ‚îÄ load_data.py
    ‚îú‚îÄ‚îÄ train_model.py
    ‚îú‚îÄ‚îÄ evaluate.py
    ‚îî‚îÄ‚îÄ compare_models.py
/notebooks/     ‚Üí An√°lisis exploratorio (opcional)
/results/       ‚Üí Modelos, m√©tricas y gr√°ficos
```
### Ejemplos de c√≥digo

```python
# Cargar datos
from src.load_data import load_fraud_csv
df, X, y = load_fraud_csv('data/creditcard.csv')
amount = X['Amount']
```
```python
# Entrenar modelo sensible al coste
from src.train_model import train_rf_with_cost
rf = train_rf_with_cost(X_train, y_train, amount_train, amount_factor=15)
```
```python
# Evaluar con coste real
from src.evaluate import expected_cost, best_threshold_by_cost
cost = expected_cost(y_test, proba, amount_test)
print(f'Costo esperado: ‚Ç¨{cost:,.2f}')
```

## Modelos Comparados

| Modelo         | Ventajas                                  | Desventajas                              |
|----------------|-------------------------------------------|------------------------------------------|
| **RandomForest** | Interpretable, robusto a outliers         | Menos sensible a pesos complejos         |
| **XGBoost**      | Mejor rendimiento en coste, optimizaci√≥n por gradiente | Menos interpretable, requiere m√°s tuning |

> **Resultado t√≠pico:** XGBoost reduce el coste esperado en **~15-25%** vs. RandomForest.

---

## M√©tricas Clave

- **Expected Financial Cost** = `(FN √ó Amount √ó 0.9) + (FP √ó 5)`
- **AUPRC** (para comparaci√≥n)
- **Mejor umbral** optimizado por coste, no por F1.

---

## Posibles Experimentos a Realizar

1. Variaci√≥n de `amount_factor` (5, 10, 15, 20)  
2. Reequilibrado por SMOTE + peso por monto  
3. Undersampling ponderado  
4. Redes neuronales con *custom loss*

## üìà Ejemplo de Resultados del c√≥digo *fraud_detection.py*

```python
from src.compare_models import compare_all_factors
compare_all_factors('data/creditcard.csv')
```
| Factor 15 | Factor 20 |
|----------|----------|
| ![Expected cost (factor=15)](results/Figure%202025-11-04%20211504.png) | ![Expected cost (factor=20)](results/Figure%202025-11-04%20211645.png) |

**Umbral √≥ptimo:** 0.3871  
**Coste m√≠nimo:** ‚Ç¨24.110  
**Ahorro vs RandomForest:** **15 %**

## Paquetes Python

```bash
pip install pandas scikit-learn xgboost imbalanced-learn matplotlib seaborn
```
