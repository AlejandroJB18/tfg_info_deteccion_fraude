# tfg_info_deteccion_fraude
Desarrollar un sistema de Machine Learning que no solo clasifique transacciones como fraudulentas o legÃ­timas, sino que **minimice la pÃ©rdida financiera total esperada**. El modelo debe aprender que un fraude de 10,000â‚¬ es significativamente mÃ¡s costoso que 10 fraudes de 100â‚¬.

### Enfoque TÃ©cnico
* **Problema Imbalanceado:** Tratamiento de la baja tasa de fraude (clase minoritaria).
* **Sensibilidad al Coste:** IncorporaciÃ³n del campo `Amount` (monto) como factor de penalizaciÃ³n durante el entrenamiento y la evaluaciÃ³n.
* **MÃ©trica Clave:** **Costo Financiero Esperado** (Expected Financial Cost), en lugar de F1-Score o Balance Accuracy.

---

## ðŸ“‚ Estructura y CÃ³digo

El cÃ³digo se diseÃ±a para una ejecuciÃ³n  **secuencial**, adecuada para entornos de desarrollo y depuraciÃ³n como **Visual Studio** o **Spyder**. El cÃ³digo se ha organizado para separar la lÃ³gica reutilizable (`src/`) de los experimentos y anÃ¡lisis finales (`notebooks/`).

```plaintext
/data/                                  â†’ Datasets (credit_card.csv, cs_training, etc.)
/exploracion/                           â†’ Notebooks de la fase inicial de investigaciÃ³n
    â”œâ”€â”€ deteccion_impago...ipynb      
    â”œâ”€â”€ varios_datasets.ipynb     
    â”œâ”€â”€ modelos_avanzados.ipynb      
/notebooks/                             â†’ AnÃ¡lisis finales
    â”œâ”€â”€ analisis_financiero.ipynb       # SimulaciÃ³n y optimizaciÃ³n del modelo
    â”œâ”€â”€ analisis_sensibilidad.ipynb     # AnÃ¡lisis de robustez de negocio
/results/                               â†’ Modelos, mÃ©tricas y grÃ¡ficos
/src/                                   â†’ MÃ³dulos Python
    â”œâ”€â”€ load_data.py                    # Carga y limpieza de datos
    â”œâ”€â”€ train_model.py                  # Entrenamiento con coste variable
    â”œâ”€â”€ evaluate.py                     # FunciÃ³n de Coste Financiero y OptimizaciÃ³n de Umbral
    â””â”€â”€ compare_models.py               # Simulaciones
README.md                               â†’ Este documento
```
### Ejemplos de cÃ³digo

```python
# 1. Cargar datos y separar importes
from src.load_data import load_fraud_csv
df, X, y = load_fraud_csv('data/credit_card.csv')

# 2. Entrenar modelo con penalizaciÃ³n variable (Amount * factor)
from src.train_model import train_xgb_with_cost
# amount_factor=20 indica que el modelo debe priorizar 20 veces mÃ¡s el importe
xgb = train_xgb_with_cost(X_train, y_train, amount_train, amount_factor=20)

# 3. Encontrar el umbral que minimiza el coste real
from src.evaluate import best_threshold_by_cost
# Coste = (FN * 90% del Importe) + (FP * 5â‚¬ inspecciÃ³n)
best_thr, min_cost = best_threshold_by_cost(y_test, proba, amount_test)
```
Dataset Credit Card Fraud Detection de Kaggle [data/creditcard.csv](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
## Modelos Comparados

| Modelo         | Ventajas                                  | Desventajas                              |
|----------------|-------------------------------------------|------------------------------------------|
| **RandomForest** | Interpretable, robusto a outliers         | Menos sensible a pesos complejos         |
| **XGBoost**      | Mejor rendimiento en coste, optimizaciÃ³n por gradiente | Menos interpretable, requiere mÃ¡s tuning |

> **Resultado tÃ­pico:** XGBoost reduce el coste esperado en **~15-25%** vs. RandomForest.

---

## MÃ©tricas Clave

- **Expected Financial Cost** = `(FN Ã— Amount Ã— 0.9) + (FP Ã— 5)`
- **AUPRC** (para comparaciÃ³n)
- **Mejor umbral** optimizado por coste, no por F1.

---

## ðŸ“ˆ Ejemplo de Resultados del cÃ³digo *fraud_detection.py*

```python
from src.compare_models import compare_all_factors
compare_all_factors('data/creditcard.csv')
```
## ðŸ“Š Resultados Reales (04-Nov-2025)

| amount_factor | Modelo   | Umbral | Coste (â‚¬) | AUPRC |
|---------------|----------|--------|-----------|-------|
| 5             | XGBoost  | 0.2575 | 1 693     | 0.8838 |
| 10            | XGBoost  | 0.3466 | 1 694     | 0.8868 |
| 15            | XGBoost  | 0.5247 | 1 689     | 0.8826 |
| 20            | XGBoost  | 0.6831 | 1 670     | 0.8819 |
| **30**        | **XGBoost** | **0.8613** | **1 661** | **0.8856** |

### Figuras generadas automÃ¡ticamente

| Coste Financiero                     | AUPRC                          |
|--------------------------------------|--------------------------------|
| ![Coste vs factor](results/Figure%202025-11-04%20211504.png) | ![AUPRC vs factor](results/Figure%202025-11-04%20211645.png) |

> **Ganador:** `XGBoost` + `amount_factor=30`  
> **Coste mÃ­nimo:** **â‚¬1 661**  
> **Ahorro:** 17 % vs RandomForest (â‚¬1 997)  
> **Fraude recuperado:** **97.24 %** de $60 127.97

## Paquetes Python

```bash
pip install pandas scikit-learn xgboost imbalanced-learn matplotlib seaborn
```
