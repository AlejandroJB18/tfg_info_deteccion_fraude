# tfg_info_deteccion_fraude
Desarrollar un sistema de Machine Learning que no solo clasifique transacciones como fraudulentas o legÃ­timas, sino que **minimice la pÃ©rdida financiera total esperada**. El modelo debe aprender que un fraude de $10,000 es significativamente mÃ¡s costoso que 10 fraudes de $100.

### Enfoque TÃ©cnico
* **Problema Imbalanceado:** Tratamiento de la baja tasa de fraude (clase minoritaria).
* **Sensibilidad al Coste:** IncorporaciÃ³n del campo `Amount` (monto) como factor de penalizaciÃ³n durante el entrenamiento y la evaluaciÃ³n.
* **MÃ©trica Clave:** **Costo Financiero Esperado** (Expected Financial Cost), en lugar de F1-Score o Accuracy.

---

## ðŸ“‚ Estructura y CÃ³digo

El cÃ³digo se diseÃ±a para una ejecuciÃ³n  **secuencial**, adecuada para entornos de desarrollo y depuraciÃ³n como **Visual Studio** o **Spyder**.

```plaintext
/data/          â†’ Datasets (creditcard.csv, etc.)
/src/           â†’ MÃ³dulos Python
    â”œâ”€â”€ load_data.py
    â”œâ”€â”€ train_model.py
    â”œâ”€â”€ evaluate.py
    â””â”€â”€ compare_models.py
/notebooks/     â†’ AnÃ¡lisis exploratorio (opcional)
/results/       â†’ Modelos, mÃ©tricas y grÃ¡ficos
```
### Ejemplos de cÃ³digo

```python
# Cargar datos
from src.load_data import load_fraud_csv
df, X, y = load_fraud_csv('data/creditcard.csv')
amount = X['Amount']
```
```python
# Entrenar modelo sensible al coste
from src.train_model import train_rf_with_cost
rf = train_rf_with_cost(X_train, y_train, amount_train, amount_factor=15)
```
```python
# Evaluar con coste real
from src.evaluate import expected_cost, best_threshold_by_cost
cost = expected_cost(y_test, proba, amount_test)
print(f'Costo esperado: â‚¬{cost:,.2f}')
```

## Modelos Comparados

| Modelo         | Ventajas                                  | Desventajas                              |
|----------------|-------------------------------------------|------------------------------------------|
| **RandomForest** | Interpretable, robusto a outliers         | Menos sensible a pesos complejos         |
| **XGBoost**      | Mejor rendimiento en coste, optimizaciÃ³n por gradiente | Menos interpretable, requiere mÃ¡s tuning |

> **Resultado tÃ­pico:** XGBoost reduce el coste esperado en **~15-25%** vs. RandomForest.

---

## MÃ©tricas Clave

- **Expected Financial Cost** = `(FN Ã— Amount Ã— 0.9) + (FP Ã— 5)`
- **AUPRC** (para comparaciÃ³n)
- **Mejor umbral** optimizado por coste, no por F1.

---

## Posibles Experimentos a Realizar

1. VariaciÃ³n de `amount_factor` (5, 10, 15, 20)  
2. Reequilibrado por SMOTE + peso por monto  
3. Undersampling ponderado  
4. Redes neuronales con *custom loss*

## ðŸ“ˆ Ejemplo de Resultados del cÃ³digo *fraud_detection.py*

```python
from src.compare_models import compare_all_factors
compare_all_factors('data/creditcard.csv')
```
## ðŸ“Š Resultados Reales (04-Nov-2025)

| amount_factor | Modelo   | Umbral | Coste (â‚¬) | AUPRC |
|---------------|----------|--------|-----------|-------|
| 5             | XGBoost  | 0.2575 | 1 693     | 0.8838 |
| 10            | XGBoost  | 0.3466 | 1 694     | 0.8868 |
| 15            | XGBoost  | 0.5247 | 1 689     | 0.8826 |
| 20            | XGBoost  | 0.6831 | 1 670     | 0.8819 |
| **30**        | **XGBoost** | **0.8613** | **1 661** | **0.8856** |

### Figuras generadas automÃ¡ticamente

| Coste Financiero                     | AUPRC                          |
|--------------------------------------|--------------------------------|
| ![Coste vs factor](results/Figure_2025-11-04_211504.png) | ![AUPRC vs factor](results/Figure_2025-11-04_211645.png) |

> **Ganador:** `XGBoost` + `amount_factor=30`  
> **Coste mÃ­nimo:** **â‚¬1 661**  
> **Ahorro:** 17 % vs RandomForest (â‚¬1 997)  
> **Fraude recuperado:** **97.24 %** de $60 127.97

## Paquetes Python

```bash
pip install pandas scikit-learn xgboost imbalanced-learn matplotlib seaborn
```
