{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark de Estrategias en M煤ltiples Datasets\n",
    "\n",
    "## Objetivo del Notebook\n",
    "\n",
    "En este notebook quiero validar si las estrategias t铆picas de balanceo funcionan igual en todos los escenarios o si dependen del dataset. Voy a probar 3 estrategias (Base, Pesos 'balanced' y SMOTE) sobre 4 datasets con distintos niveles de desbalanceo (desde el alem谩n que es peque帽o hasta el de fraude de tarjetas que es masivo).\n",
    "\n",
    "La idea es tener una visi贸n general antes de meterme a optimizar modelos complejos.\n",
    "\n",
    "**Estrategias a Comparar:**\n",
    "1.  **Estrategia 1: Convencional** (L铆nea Base).\n",
    "2.  **Estrategia 2: Coste Sensible Fijo** (Usando `class_weight='balanced'`).\n",
    "3.  **Estrategia 3: Balanceo de Datos** (Usando `SMOTE`).\n",
    "\n",
    "**M茅tricas Clave:**\n",
    "* **`Balanced Accuracy`:** Mide el equilibrio general del modelo.\n",
    "* **`F1-Score (Clase Minoritaria)`:** Mide la efectividad (equilibrio Precisi贸n/Recall) para detectar la clase \"Mal Riesgo\" o \"Fraude\", que es nuestro objetivo principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Modelos a comparar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# M茅tricas y utilidades\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score\n",
    "from IPython.display import display\n",
    "\n",
    "# Mis funciones del m贸dulo src\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.benchmark_utils import evaluate_models, evaluate_cost_sensitive_models, evaluate_smote_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definici贸n de Modelos a Probar\n",
    "\n",
    "Se seleccionan tres tipos de modelos representativos: Regresi贸n Log铆stica (lineal), rbol de Decisi贸n (谩rbol simple) y Random Forest (ensamble de 谩rboles).\n",
    "\n",
    "**Nota sobre SVC (Support Vector Classifier):**\n",
    "Aunque `SVC` fue importado en la celda anterior, se ha **comentado y excluido** de este benchmark (`models_to_test`).\n",
    "\n",
    "La raz贸n es su **alto coste computacional**. El tiempo de entrenamiento de SVC escala de forma cuadr谩tica o c煤bica ($O(n^2)$ a $O(n^3)$) con el n煤mero de muestras. Ejecutarlo en datasets grandes como \"Credit Card Fraud\" (284k muestras) o \"Give Me Some Credit\" (150k muestras) bajo 3 estrategias diferentes (36* ejecuciones) har铆a que el notebook tardara horas en completarse.\n",
    "\n",
    "El `SVC` s铆 se analiza en profundidad en el notebook `modelos_convencionales_german_credit_data.ipynb`, que utiliza un dataset m谩s peque帽o (1000 muestras) donde su coste es manejable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=2000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    #'SVC': SVC(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Diccionario de datasets (con \"Give Me Some Credit\" activado)\n",
    "datasets_to_test = {\n",
    "    'German Credit': {'source': 'openml', 'id': 31, 'target_col': 'class'},\n",
    "    'Taiwan Credit Default': {'source': 'openml', 'id': 42477, 'target_col': 'class'},\n",
    "    'Credit Card Fraud': {'source': 'openml', 'id': 1597, 'target_col': 'class'},\n",
    "    'Give Me Some Credit': {'source': 'csv', 'path': '../data/cs-training.csv', 'target_col': 'SeriousDlqin2yrs'}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Estrategia Base (Sin balanceo)\n",
    "\n",
    "Se definen los 4 datasets a probar: German Credit, Taiwan Credit Default, Credit Card Fraud y Give Me Some Credit.\n",
    "\n",
    "Un paso clave en la carga de datos es **mapear la variable objetivo (y)** para que la **clase minoritaria (impago/fraude) sea siempre 1** y la mayoritaria sea 0. Esto estandariza la evaluaci贸n.\n",
    "\n",
    "A continuaci贸n, se ejecuta el benchmark convencional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO BENCHMARK (1. CONVENCIONAL)\n",
      "\n",
      "--- Cargando y procesando dataset: German Credit ---\n",
      "Mapeando: 'good' (Mayoritaria) -> 0, 'bad' (Minoritaria) -> 1\n",
      "--- Evaluando Dataset: German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi贸n:\n",
      "[[187  23]\n",
      " [ 42  48]]\n",
      "Balanced Accuracy: 0.712\n",
      "F1-Score (clase 'mala'): 0.596\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi贸n:\n",
      "[[196  14]\n",
      " [ 55  35]]\n",
      "Balanced Accuracy: 0.661\n",
      "F1-Score (clase 'mala'): 0.504\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi贸n:\n",
      "[[158  52]\n",
      " [ 51  39]]\n",
      "Balanced Accuracy: 0.593\n",
      "F1-Score (clase 'mala'): 0.431\n",
      "Evaluaci贸n convencional para German Credit completada.\n",
      "\n",
      "--- Cargando y procesando dataset: Taiwan Credit Default ---\n",
      "Mapeando: '0' (Mayoritaria) -> 0, '1' (Minoritaria) -> 1\n",
      "--- Evaluando Dataset: Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi贸n:\n",
      "[[6805  204]\n",
      " [1521  470]]\n",
      "Balanced Accuracy: 0.603\n",
      "F1-Score (clase 'mala'): 0.353\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi贸n:\n",
      "[[6598  411]\n",
      " [1270  721]]\n",
      "Balanced Accuracy: 0.652\n",
      "F1-Score (clase 'mala'): 0.462\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi贸n:\n",
      "[[5710 1299]\n",
      " [1188  803]]\n",
      "Balanced Accuracy: 0.609\n",
      "F1-Score (clase 'mala'): 0.392\n",
      "Evaluaci贸n convencional para Taiwan Credit Default completada.\n",
      "\n",
      "--- Cargando y procesando dataset: Credit Card Fraud ---\n",
      "Mapeando: '0' (Mayoritaria) -> 0, '1' (Minoritaria) -> 1\n",
      "--- Evaluando Dataset: Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi贸n:\n",
      "[[85280    15]\n",
      " [   57    91]]\n",
      "Balanced Accuracy: 0.807\n",
      "F1-Score (clase 'mala'): 0.717\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi贸n:\n",
      "[[85290     5]\n",
      " [   35   113]]\n",
      "Balanced Accuracy: 0.882\n",
      "F1-Score (clase 'mala'): 0.850\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi贸n:\n",
      "[[85269    26]\n",
      " [   39   109]]\n",
      "Balanced Accuracy: 0.868\n",
      "F1-Score (clase 'mala'): 0.770\n",
      "Evaluaci贸n convencional para Credit Card Fraud completada.\n",
      "\n",
      "--- Cargando y procesando dataset: Give Me Some Credit ---\n",
      "--- Evaluando Dataset: Give Me Some Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi贸n:\n",
      "[[41898    94]\n",
      " [ 2883   125]]\n",
      "Balanced Accuracy: 0.520\n",
      "F1-Score (clase 'mala'): 0.077\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi贸n:\n",
      "[[41555   437]\n",
      " [ 2453   555]]\n",
      "Balanced Accuracy: 0.587\n",
      "F1-Score (clase 'mala'): 0.278\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi贸n:\n",
      "[[39631  2361]\n",
      " [ 2147   861]]\n",
      "Balanced Accuracy: 0.615\n",
      "F1-Score (clase 'mala'): 0.276\n",
      "Evaluaci贸n convencional para Give Me Some Credit completada.\n",
      "\n",
      "--- TABLA COMPARATIVA (1. Convencional) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>0.276404</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519659</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.651745</td>\n",
       "      <td>0.461736</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.608991</td>\n",
       "      <td>0.392377</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.603478</td>\n",
       "      <td>0.352720</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy  \\\n",
       "7       Credit Card Fraud        Random Forest           0.881727   \n",
       "8       Credit Card Fraud        Decision Tree           0.868091   \n",
       "6       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "2           German Credit        Decision Tree           0.592857   \n",
       "11    Give Me Some Credit        Decision Tree           0.615006   \n",
       "10    Give Me Some Credit        Random Forest           0.587051   \n",
       "9     Give Me Some Credit  Logistic Regression           0.519659   \n",
       "4   Taiwan Credit Default        Random Forest           0.651745   \n",
       "5   Taiwan Credit Default        Decision Tree           0.608991   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.603478   \n",
       "\n",
       "    f1_score_bad_class             Tipo  \n",
       "7             0.849624  1. Convencional  \n",
       "8             0.770318  1. Convencional  \n",
       "6             0.716535  1. Convencional  \n",
       "0             0.596273  1. Convencional  \n",
       "1             0.503597  1. Convencional  \n",
       "2             0.430939  1. Convencional  \n",
       "11            0.276404  1. Convencional  \n",
       "10            0.277500  1. Convencional  \n",
       "9             0.077471  1. Convencional  \n",
       "4             0.461736  1. Convencional  \n",
       "5             0.392377  1. Convencional  \n",
       "3             0.352720  1. Convencional  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lista para guardar los resultados convencionales\n",
    "all_results_conv = []\n",
    "\n",
    "print(\"INICIANDO BENCHMARK (1. CONVENCIONAL)\")\n",
    "\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        print(f\"\\n Dataset: {name}\")\n",
    "        \n",
    "        # Carga de datos\n",
    "        if info['source'] == 'openml':\n",
    "            data = fetch_openml(data_id=info['id'], as_frame=True, parser='auto')\n",
    "            X = data.data\n",
    "            y_raw = data.target if 'target' in data else data['class']\n",
    "\n",
    "            # Ajustamos las etiquetas para que minoritaria = 1\n",
    "            y_str = y_raw.astype(str)\n",
    "            counts = y_str.value_counts()\n",
    "\n",
    "            if len(counts) > 2:\n",
    "                print(f\"Aviso: El dataset {name} tiene m谩s de 2 clases.\")\n",
    "                y = pd.Series(pd.factorize(y_raw)[0], index=y_raw.index)\n",
    "            else:\n",
    "                minority_label = counts.idxmin()\n",
    "                majority_label = counts.idxmax()\n",
    "                \n",
    "                print(f\"Mapeando: '{majority_label}' (Mayoritaria) -> 0, '{minority_label}' (Minoritaria) -> 1\")\n",
    "                y = y_str.map({majority_label: 0, minority_label: 1}).astype(int)\n",
    "                y.index = y_raw.index # Preservar el 铆ndice\n",
    "\n",
    "\n",
    "        elif info['source'] == 'csv':\n",
    "            df = pd.read_csv(info['path'])\n",
    "            # Asumimos que la primera columna (Unnamed: 0) es un 铆ndice y la quitamos\n",
    "            if 'Unnamed: 0' in df.columns:\n",
    "                df = df.drop(columns=['Unnamed: 0'])\n",
    "            X = df.drop(columns=[info['target_col']])\n",
    "            y_raw = df[info['target_col']]\n",
    "            # El dataset CSV tiene valores nulos, los rellenamos con la media\n",
    "            X = X.fillna(X.mean())\n",
    "\n",
    "            # Este dataset ya es 0 (bueno) y 1 (malo). \n",
    "            y = y_raw.astype(int)\n",
    "\n",
    "        \n",
    "        # Guardar los datos para las siguientes ejecuciones\n",
    "        info['X_data'] = X\n",
    "        info['y_data'] = y\n",
    "\n",
    "        results = evaluate_models(X, y, models_to_test, name)\n",
    "        all_results_conv.extend(results)\n",
    "        print(f\"Evaluaci贸n convencional para {name} completada.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo procesar el dataset {name}. Error: {e}\")\n",
    "\n",
    "# Resultados\n",
    "final_results_conv_df = pd.DataFrame(all_results_conv)\n",
    "print(\"\\n--- TABLA COMPARATIVA (1. Convencional) ---\")\n",
    "display(final_results_conv_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Resultados del Benchmark Convencional\n",
    "\n",
    "La tabla de resultados y la de promedios demuestran el problema central:\n",
    "\n",
    "* **Fracaso Total en Desbalanceo Extremo:** En \"Give Me Some Credit\" (6.7% de impagos), la Regresi贸n Log铆stica convencional obtiene un **F1-Score de 0.077**. Esto es un fracaso total: el modelo no tiene ninguna capacidad real de detectar impagos.\n",
    "* **Precisi贸n Enga帽osa:** En \"Credit Card Fraud\" (0.17% de fraude), los modelos convencionales (especialmente RF y DT) obtienen un `Balanced Accuracy` y un `F1-Score` altos (ej. RF F1-Score 0.850). Esto se debe a que el conjunto de prueba es muy peque帽o y los modelos \"tuvieron suerte\", pero esta m茅trica es enga帽osa, como veremos.\n",
    "* **L铆nea Base Promedio:** En promedio, el Random Forest (Bal. Acc. 0.695) es el mejor modelo convencional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RENDIMIENTO MEDIO POR MODELO CONVENCIONAL (TODOS LOS DATASETS) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.695409</td>\n",
       "      <td>0.523114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.671236</td>\n",
       "      <td>0.467510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.660597</td>\n",
       "      <td>0.435750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     balanced_accuracy  f1_score_bad_class\n",
       "model                                                     \n",
       "Random Forest                 0.695409            0.523114\n",
       "Decision Tree                 0.671236            0.467510\n",
       "Logistic Regression           0.660597            0.435750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\" RENDIMIENTO MEDIO POR MODELO CONVENCIONAL (TODOS LOS DATASETS) \")\n",
    "\n",
    "# Agrupamos por 'model' y calculamos la media de las m茅tricas\n",
    "average_performance = final_results_conv_df.groupby('model')[['balanced_accuracy', 'f1_score_bad_class']].mean()\n",
    "\n",
    "# Ordenamos por la m茅trica que consideremos m谩s importante para ver el ranking\n",
    "average_performance_sorted = average_performance.sort_values(by='balanced_accuracy', ascending=False)\n",
    "\n",
    "display(average_performance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Estrategias de Balanceo (Pesos y SMOTE)\n",
    "\n",
    "Ahora pruebo dos enfoques para intentar arreglar el desastre de los modelos lineales en datasets desbalanceados:\n",
    "1.  **Cost Sensitive:** Pasar `class_weight='balanced'` al modelo.\n",
    "2.  **SMOTE:** Crear datos sint茅ticos en el train.\n",
    "\n",
    "Uso las funciones `evaluate_cost_sensitive_models` y `evaluate_smote_models` que se recogen dentro de `benchmark_utils.py` en la carpeta src."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INICIANDO BENCHMARK (2. COSTE SENSIBLE)\n",
      "\n",
      "Procesando German Credit (Coste Sensible)...\n",
      "--- Evaluando Dataset (Sensible a Costes): German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[150  60]\n",
      " [ 21  69]]\n",
      "Balanced Accuracy: 0.740\n",
      "F1-Score (clase 'mala'): 0.630\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.88      0.71      0.79       210\n",
      "     Clase 1       0.53      0.77      0.63        90\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.71      0.74      0.71       300\n",
      "weighted avg       0.77      0.73      0.74       300\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[194  16]\n",
      " [ 61  29]]\n",
      "Balanced Accuracy: 0.623\n",
      "F1-Score (clase 'mala'): 0.430\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.76      0.92      0.83       210\n",
      "     Clase 1       0.64      0.32      0.43        90\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.70      0.62      0.63       300\n",
      "weighted avg       0.73      0.74      0.71       300\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[155  55]\n",
      " [ 50  40]]\n",
      "Balanced Accuracy: 0.591\n",
      "F1-Score (clase 'mala'): 0.432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.76      0.74      0.75       210\n",
      "     Clase 1       0.42      0.44      0.43        90\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.59      0.59      0.59       300\n",
      "weighted avg       0.66      0.65      0.65       300\n",
      "\n",
      "Evaluaci贸n CSL para German Credit completada.\n",
      "\n",
      "Procesando Taiwan Credit Default (Coste Sensible)...\n",
      "--- Evaluando Dataset (Sensible a Costes): Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[4903 2106]\n",
      " [ 740 1251]]\n",
      "Balanced Accuracy: 0.664\n",
      "F1-Score (clase 'mala'): 0.468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.87      0.70      0.78      7009\n",
      "     Clase 1       0.37      0.63      0.47      1991\n",
      "\n",
      "    accuracy                           0.68      9000\n",
      "   macro avg       0.62      0.66      0.62      9000\n",
      "weighted avg       0.76      0.68      0.71      9000\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[6629  380]\n",
      " [1304  687]]\n",
      "Balanced Accuracy: 0.645\n",
      "F1-Score (clase 'mala'): 0.449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.84      0.95      0.89      7009\n",
      "     Clase 1       0.64      0.35      0.45      1991\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.74      0.65      0.67      9000\n",
      "weighted avg       0.79      0.81      0.79      9000\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[5827 1182]\n",
      " [1185  806]]\n",
      "Balanced Accuracy: 0.618\n",
      "F1-Score (clase 'mala'): 0.405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.83      0.83      0.83      7009\n",
      "     Clase 1       0.41      0.40      0.41      1991\n",
      "\n",
      "    accuracy                           0.74      9000\n",
      "   macro avg       0.62      0.62      0.62      9000\n",
      "weighted avg       0.74      0.74      0.74      9000\n",
      "\n",
      "Evaluaci贸n CSL para Taiwan Credit Default completada.\n",
      "\n",
      "Procesando Credit Card Fraud (Coste Sensible)...\n",
      "--- Evaluando Dataset (Sensible a Costes): Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[83407  1888]\n",
      " [   19   129]]\n",
      "Balanced Accuracy: 0.925\n",
      "F1-Score (clase 'mala'): 0.119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      0.98      0.99     85295\n",
      "     Clase 1       0.06      0.87      0.12       148\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.92      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[85292     3]\n",
      " [   44   104]]\n",
      "Balanced Accuracy: 0.851\n",
      "F1-Score (clase 'mala'): 0.816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.97      0.70      0.82       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.99      0.85      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[85263    32]\n",
      " [   52    96]]\n",
      "Balanced Accuracy: 0.824\n",
      "F1-Score (clase 'mala'): 0.696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.75      0.65      0.70       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.87      0.82      0.85     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Evaluaci贸n CSL para Credit Card Fraud completada.\n",
      "\n",
      "Procesando Give Me Some Credit (Coste Sensible)...\n",
      "--- Evaluando Dataset (Sensible a Costes): Give Me Some Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[32956  9036]\n",
      " [ 1026  1982]]\n",
      "Balanced Accuracy: 0.722\n",
      "F1-Score (clase 'mala'): 0.283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.97      0.78      0.87     41992\n",
      "     Clase 1       0.18      0.66      0.28      3008\n",
      "\n",
      "    accuracy                           0.78     45000\n",
      "   macro avg       0.57      0.72      0.58     45000\n",
      "weighted avg       0.92      0.78      0.83     45000\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[41646   346]\n",
      " [ 2547   461]]\n",
      "Balanced Accuracy: 0.573\n",
      "F1-Score (clase 'mala'): 0.242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.94      0.99      0.97     41992\n",
      "     Clase 1       0.57      0.15      0.24      3008\n",
      "\n",
      "    accuracy                           0.94     45000\n",
      "   macro avg       0.76      0.57      0.60     45000\n",
      "weighted avg       0.92      0.94      0.92     45000\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi贸n:\n",
      "[[39831  2161]\n",
      " [ 2262   746]]\n",
      "Balanced Accuracy: 0.598\n",
      "F1-Score (clase 'mala'): 0.252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.95      0.95      0.95     41992\n",
      "     Clase 1       0.26      0.25      0.25      3008\n",
      "\n",
      "    accuracy                           0.90     45000\n",
      "   macro avg       0.60      0.60      0.60     45000\n",
      "weighted avg       0.90      0.90      0.90     45000\n",
      "\n",
      "Evaluaci贸n CSL para Give Me Some Credit completada.\n",
      "\n",
      "--- TABLA COMPARATIVA (2. Coste Sensible) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.924743</td>\n",
       "      <td>0.119169</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.851334</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.824137</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721863</td>\n",
       "      <td>0.282618</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.598272</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.572509</td>\n",
       "      <td>0.241678</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.663928</td>\n",
       "      <td>0.467838</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.645418</td>\n",
       "      <td>0.449313</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.618091</td>\n",
       "      <td>0.405127</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy  \\\n",
       "6       Credit Card Fraud  Logistic Regression           0.924743   \n",
       "7       Credit Card Fraud        Random Forest           0.851334   \n",
       "8       Credit Card Fraud        Decision Tree           0.824137   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "1           German Credit        Random Forest           0.623016   \n",
       "2           German Credit        Decision Tree           0.591270   \n",
       "9     Give Me Some Credit  Logistic Regression           0.721863   \n",
       "11    Give Me Some Credit        Decision Tree           0.598272   \n",
       "10    Give Me Some Credit        Random Forest           0.572509   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.663928   \n",
       "4   Taiwan Credit Default        Random Forest           0.645418   \n",
       "5   Taiwan Credit Default        Decision Tree           0.618091   \n",
       "\n",
       "    f1_score_bad_class                              Tipo  \n",
       "6             0.119169  2. Coste Sensible (class_weight)  \n",
       "7             0.815686  2. Coste Sensible (class_weight)  \n",
       "8             0.695652  2. Coste Sensible (class_weight)  \n",
       "0             0.630137  2. Coste Sensible (class_weight)  \n",
       "1             0.429630  2. Coste Sensible (class_weight)  \n",
       "2             0.432432  2. Coste Sensible (class_weight)  \n",
       "9             0.282618  2. Coste Sensible (class_weight)  \n",
       "11            0.252240  2. Coste Sensible (class_weight)  \n",
       "10            0.241678  2. Coste Sensible (class_weight)  \n",
       "3             0.467838  2. Coste Sensible (class_weight)  \n",
       "4             0.449313  2. Coste Sensible (class_weight)  \n",
       "5             0.405127  2. Coste Sensible (class_weight)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results_cs = []\n",
    "print(\"\\nINICIANDO BENCHMARK (2. COSTE SENSIBLE)\")\n",
    "\n",
    "# Este bucle ahora REUTILIZA los datos X e y cargados en la celda anterior\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        if 'X_data' in info:\n",
    "            print(f\"\\nProcesando {name} (Coste Sensible)...\")\n",
    "            # Llamar a la funci贸n de evaluaci贸n de COSTE SENSIBLE (celda [9])\n",
    "            results_cs = evaluate_cost_sensitive_models(info['X_data'], info['y_data'], models_to_test, name)\n",
    "            all_results_cs.extend(results_cs)\n",
    "            print(f\"Evaluaci贸n CSL para {name} completada.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Saltando {name} (no se cargaron los datos en el paso anterior).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo procesar el dataset {name} (CSL). Error: {e}\")\n",
    "\n",
    "final_results_cs_df = pd.DataFrame(all_results_cs)\n",
    "print(\"\\n--- TABLA COMPARATIVA (2. Coste Sensible) ---\")\n",
    "display(final_results_cs_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Resultados del Benchmark CSL (`class_weight='balanced'`)\n",
    "\n",
    "Los resultados de CSL revelan un patr贸n fundamental:\n",
    "\n",
    "* **Mejora en Desbalanceo Moderado:** En \"Give Me Some Credit\" (6.7%), el CSL mejora dr谩sticamente el F1-Score de la Regresi贸n Log铆stica (de 0.077 a **0.283**).\n",
    "* **Fracaso en Desbalanceo Extremo:** En \"Credit Card Fraud\" (0.17%), el CSL (`'balanced'`) es **desastroso**. El F1-Score de la Regresi贸n Log铆stica colapsa de 0.717 (convencional) a **0.119**.\n",
    "* **Fallo en Random Forest:** La `Balanced Accuracy` promedio de RF *empeora* (de 0.695 a 0.673).\n",
    "\n",
    "**Conclusi贸n clave:** `class_weight='balanced'` funciona para modelos lineales en desbalanceo *moderado*, pero **falla estrepitosamente** en desbalanceo *extremo* (colapsa el F1-Score) y no funciona bien con Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- RENDIMIENTO MEDIO POR MODELO COSTE (TODOS LOS DATASETS) --- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.762753</td>\n",
       "      <td>0.374941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.673069</td>\n",
       "      <td>0.484077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.657942</td>\n",
       "      <td>0.446363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     balanced_accuracy  f1_score_bad_class\n",
       "model                                                     \n",
       "Logistic Regression           0.762753            0.374941\n",
       "Random Forest                 0.673069            0.484077\n",
       "Decision Tree                 0.657942            0.446363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\" RENDIMIENTO MEDIO POR MODELO COSTE (TODOS LOS DATASETS)\")\n",
    "\n",
    "# Agrupamos por 'model' y calculamos la media de las m茅tricas\n",
    "average_performance = final_results_cs_df.groupby('model')[['balanced_accuracy', 'f1_score_bad_class']].mean()\n",
    "\n",
    "# Ordenamos por la m茅trica que consideremos m谩s importante para ver el ranking\n",
    "average_performance_sorted = average_performance.sort_values(by='balanced_accuracy', ascending=False)\n",
    "\n",
    "display(average_performance_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INICIANDO BENCHMARK (3. BALANCEO SMOTE)\n",
      "\n",
      "Procesando German Credit (SMOTE)...\n",
      "--- Evaluando Dataset (Balanceo SMOTE): German Credit ---\n",
      "Evaluaci贸n SMOTE para German Credit completada.\n",
      "\n",
      "Procesando Taiwan Credit Default (SMOTE)...\n",
      "--- Evaluando Dataset (Balanceo SMOTE): Taiwan Credit Default ---\n",
      "Evaluaci贸n SMOTE para Taiwan Credit Default completada.\n",
      "\n",
      "Procesando Credit Card Fraud (SMOTE)...\n",
      "--- Evaluando Dataset (Balanceo SMOTE): Credit Card Fraud ---\n",
      "Evaluaci贸n SMOTE para Credit Card Fraud completada.\n",
      "\n",
      "Procesando Give Me Some Credit (SMOTE)...\n",
      "--- Evaluando Dataset (Balanceo SMOTE): Give Me Some Credit ---\n",
      "Evaluaci贸n SMOTE para Give Me Some Credit completada.\n",
      "\n",
      "--- TABLA COMPARATIVA (3. Balanceo SMOTE) --- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.930873</td>\n",
       "      <td>0.115215</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.891804</td>\n",
       "      <td>0.831541</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.522876</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.716450</td>\n",
       "      <td>0.268322</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.647169</td>\n",
       "      <td>0.352529</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.622387</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.676932</td>\n",
       "      <td>0.501361</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.660037</td>\n",
       "      <td>0.462741</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.616844</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy  \\\n",
       "6       Credit Card Fraud  Logistic Regression           0.930873   \n",
       "7       Credit Card Fraud        Random Forest           0.891804   \n",
       "8       Credit Card Fraud        Decision Tree           0.873927   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "1           German Credit        Random Forest           0.667460   \n",
       "2           German Credit        Decision Tree           0.580952   \n",
       "9     Give Me Some Credit  Logistic Regression           0.716450   \n",
       "10    Give Me Some Credit        Random Forest           0.647169   \n",
       "11    Give Me Some Credit        Decision Tree           0.622387   \n",
       "4   Taiwan Credit Default        Random Forest           0.676932   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.660037   \n",
       "5   Taiwan Credit Default        Decision Tree           0.616844   \n",
       "\n",
       "    f1_score_bad_class                 Tipo  \n",
       "6             0.115215  3. Balanceo (SMOTE)  \n",
       "7             0.831541  3. Balanceo (SMOTE)  \n",
       "8             0.502262  3. Balanceo (SMOTE)  \n",
       "0             0.631579  3. Balanceo (SMOTE)  \n",
       "1             0.522876  3. Balanceo (SMOTE)  \n",
       "2             0.409091  3. Balanceo (SMOTE)  \n",
       "9             0.268322  3. Balanceo (SMOTE)  \n",
       "10            0.352529  3. Balanceo (SMOTE)  \n",
       "11            0.250965  3. Balanceo (SMOTE)  \n",
       "4             0.501361  3. Balanceo (SMOTE)  \n",
       "3             0.462741  3. Balanceo (SMOTE)  \n",
       "5             0.408163  3. Balanceo (SMOTE)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results_smote = []\n",
    "print(\"\\nINICIANDO BENCHMARK (3. BALANCEO SMOTE)\")\n",
    "\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        if 'X_data' in info: \n",
    "            print(f\"\\nProcesando {name} (SMOTE)...\")            \n",
    "            results_smote = evaluate_smote_models(info['X_data'], info['y_data'], models_to_test, name)\n",
    "            all_results_smote.extend(results_smote)\n",
    "            print(f\"Evaluaci贸n SMOTE para {name} completada.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Saltando {name} (no se cargaron los datos).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo procesar el dataset {name} (SMOTE). Error: {e}\")\n",
    "\n",
    "final_results_smote_df = pd.DataFrame(all_results_smote)\n",
    "print(\"\\n--- TABLA COMPARATIVA (3. Balanceo SMOTE) --- \")\n",
    "display(final_results_smote_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RENDIMIENTO MEDIO POR MODELO COSTE (TODOS LOS DATASETS) --- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.761959</td>\n",
       "      <td>0.369464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.720841</td>\n",
       "      <td>0.552077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.673528</td>\n",
       "      <td>0.392620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     balanced_accuracy  f1_score_bad_class\n",
       "model                                                     \n",
       "Logistic Regression           0.761959            0.369464\n",
       "Random Forest                 0.720841            0.552077\n",
       "Decision Tree                 0.673528            0.392620"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"RENDIMIENTO MEDIO POR MODELO SMOTE (TODOS LOS DATASETS) \")\n",
    "\n",
    "# Agrupamos por 'model' y calculamos la media de las m茅tricas\n",
    "average_performance = final_results_smote_df.groupby('model')[['balanced_accuracy', 'f1_score_bad_class']].mean()\n",
    "\n",
    "# Ordenamos por la m茅trica que consideremos m谩s importante para ver el ranking\n",
    "average_performance_sorted = average_performance.sort_values(by='balanced_accuracy', ascending=False)\n",
    "\n",
    "display(average_performance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Resultados del Benchmark SMOTE\n",
    "\n",
    "Los resultados de SMOTE (visibles en la tabla de la celda 13) muestran un patr贸n diferente:\n",
    "\n",
    "* **xito en Regresi贸n Log铆stica:** Al igual que CSL, SMOTE **mejora dr谩sticamente** el rendimiento de LR (promedio de 0.661 a 0.762).\n",
    "* **xito en Random Forest:** A diferencia de CSL, SMOTE **s铆 mejora** el rendimiento de RF (promedio de 0.695 a 0.720).\n",
    "\n",
    "Esto sugiere que los modelos de Random Forest se benefician m谩s de ver un conjunto de datos balanceado (SMOTE) que de una penalizaci贸n interna (CSL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TABLA COMPARATIVA FINAL: ESTRATEGIAS vs. DATASETS ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.824137</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.924743</td>\n",
       "      <td>0.119169</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.930873</td>\n",
       "      <td>0.115215</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.851334</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.891804</td>\n",
       "      <td>0.831541</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.522876</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>0.276404</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.598272</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.622387</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519659</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721863</td>\n",
       "      <td>0.282618</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.716450</td>\n",
       "      <td>0.268322</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.572509</td>\n",
       "      <td>0.241678</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.647169</td>\n",
       "      <td>0.352529</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.608991</td>\n",
       "      <td>0.392377</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.618091</td>\n",
       "      <td>0.405127</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.616844</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.603478</td>\n",
       "      <td>0.352720</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.663928</td>\n",
       "      <td>0.467838</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.660037</td>\n",
       "      <td>0.462741</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.651745</td>\n",
       "      <td>0.461736</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.645418</td>\n",
       "      <td>0.449313</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.676932</td>\n",
       "      <td>0.501361</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy  \\\n",
       "8       Credit Card Fraud        Decision Tree           0.868091   \n",
       "8       Credit Card Fraud        Decision Tree           0.824137   \n",
       "8       Credit Card Fraud        Decision Tree           0.873927   \n",
       "6       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "6       Credit Card Fraud  Logistic Regression           0.924743   \n",
       "6       Credit Card Fraud  Logistic Regression           0.930873   \n",
       "7       Credit Card Fraud        Random Forest           0.881727   \n",
       "7       Credit Card Fraud        Random Forest           0.851334   \n",
       "7       Credit Card Fraud        Random Forest           0.891804   \n",
       "2           German Credit        Decision Tree           0.592857   \n",
       "2           German Credit        Decision Tree           0.591270   \n",
       "2           German Credit        Decision Tree           0.580952   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "1           German Credit        Random Forest           0.623016   \n",
       "1           German Credit        Random Forest           0.667460   \n",
       "11    Give Me Some Credit        Decision Tree           0.615006   \n",
       "11    Give Me Some Credit        Decision Tree           0.598272   \n",
       "11    Give Me Some Credit        Decision Tree           0.622387   \n",
       "9     Give Me Some Credit  Logistic Regression           0.519659   \n",
       "9     Give Me Some Credit  Logistic Regression           0.721863   \n",
       "9     Give Me Some Credit  Logistic Regression           0.716450   \n",
       "10    Give Me Some Credit        Random Forest           0.587051   \n",
       "10    Give Me Some Credit        Random Forest           0.572509   \n",
       "10    Give Me Some Credit        Random Forest           0.647169   \n",
       "5   Taiwan Credit Default        Decision Tree           0.608991   \n",
       "5   Taiwan Credit Default        Decision Tree           0.618091   \n",
       "5   Taiwan Credit Default        Decision Tree           0.616844   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.603478   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.663928   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.660037   \n",
       "4   Taiwan Credit Default        Random Forest           0.651745   \n",
       "4   Taiwan Credit Default        Random Forest           0.645418   \n",
       "4   Taiwan Credit Default        Random Forest           0.676932   \n",
       "\n",
       "    f1_score_bad_class                              Tipo  \n",
       "8             0.770318                   1. Convencional  \n",
       "8             0.695652  2. Coste Sensible (class_weight)  \n",
       "8             0.502262               3. Balanceo (SMOTE)  \n",
       "6             0.716535                   1. Convencional  \n",
       "6             0.119169  2. Coste Sensible (class_weight)  \n",
       "6             0.115215               3. Balanceo (SMOTE)  \n",
       "7             0.849624                   1. Convencional  \n",
       "7             0.815686  2. Coste Sensible (class_weight)  \n",
       "7             0.831541               3. Balanceo (SMOTE)  \n",
       "2             0.430939                   1. Convencional  \n",
       "2             0.432432  2. Coste Sensible (class_weight)  \n",
       "2             0.409091               3. Balanceo (SMOTE)  \n",
       "0             0.596273                   1. Convencional  \n",
       "0             0.630137  2. Coste Sensible (class_weight)  \n",
       "0             0.631579               3. Balanceo (SMOTE)  \n",
       "1             0.503597                   1. Convencional  \n",
       "1             0.429630  2. Coste Sensible (class_weight)  \n",
       "1             0.522876               3. Balanceo (SMOTE)  \n",
       "11            0.276404                   1. Convencional  \n",
       "11            0.252240  2. Coste Sensible (class_weight)  \n",
       "11            0.250965               3. Balanceo (SMOTE)  \n",
       "9             0.077471                   1. Convencional  \n",
       "9             0.282618  2. Coste Sensible (class_weight)  \n",
       "9             0.268322               3. Balanceo (SMOTE)  \n",
       "10            0.277500                   1. Convencional  \n",
       "10            0.241678  2. Coste Sensible (class_weight)  \n",
       "10            0.352529               3. Balanceo (SMOTE)  \n",
       "5             0.392377                   1. Convencional  \n",
       "5             0.405127  2. Coste Sensible (class_weight)  \n",
       "5             0.408163               3. Balanceo (SMOTE)  \n",
       "3             0.352720                   1. Convencional  \n",
       "3             0.467838  2. Coste Sensible (class_weight)  \n",
       "3             0.462741               3. Balanceo (SMOTE)  \n",
       "4             0.461736                   1. Convencional  \n",
       "4             0.449313  2. Coste Sensible (class_weight)  \n",
       "4             0.501361               3. Balanceo (SMOTE)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results_conv_df['Tipo'] = '1. Convencional'\n",
    "final_results_cs_df['Tipo'] = '2. Coste Sensible (class_weight)'\n",
    "final_results_smote_df['Tipo'] = '3. Balanceo (SMOTE)' \n",
    "\n",
    "# Unimos las TRES tablas de resultados\n",
    "comparison_df = pd.concat([final_results_conv_df, final_results_cs_df, final_results_smote_df]) \n",
    "\n",
    "# Mostramos la tabla final, ordenada para facilitar la comparaci贸n\n",
    "print(\"--- TABLA COMPARATIVA FINAL: ESTRATEGIAS vs. DATASETS ---\")\n",
    "display(comparison_df.sort_values(by=['dataset', 'model', 'Tipo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusiones Finales del Benchmark\n",
    "\n",
    "La tabla comparativa final consolida los hallazgos:\n",
    "\n",
    "1.  **Para Regresi贸n Log铆stica (Lineal):**\n",
    "    * En desbalanceo **moderado** (\"German Credit\", \"Taiwan\"), tanto **CSL (`'balanced'`)** como **SMOTE** son estrategias excelentes y muy similares, mejorando tanto `Balanced Accuracy` como `F1-Score` (ej. German F1-Score: 0.596 -> **0.630**).\n",
    "    * En desbalanceo **extremo** (\"Credit Card Fraud\"), ambas estrategias **fallan**, colapsando el `F1-Score` (0.717 -> **0.119** con CSL y **0.115** con SMOTE).\n",
    "\n",
    "2.  **Para Random Forest (Bagging):**\n",
    "    * **SMOTE** es la estrategia ganadora en promedio (mejora F1 de 0.523 a 0.552).\n",
    "    * **CSL (`'balanced'`)** es una mala estrategia; empeora tanto la `Balanced Accuracy` como el `F1-Score` en promedio.\n",
    "\n",
    "**Conclusi贸n General:** Este notebook justifica la necesidad de estrategias m谩s avanzadas. `class_weight='balanced'` y `SMOTE` (con par谩metros por defecto) no son soluciones universales y **fallan en los casos de desbalanceo extremo**, que es donde se centra el notebook `modelos_avanzados.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones r谩pidas\n",
    "\n",
    "1.  **Regresi贸n Log铆stica:** Necesita ayuda s铆 o s铆. Tanto los pesos como SMOTE la reviven en datasets dif铆ciles, aunque en el de fraude extremo sigue sufriendo.\n",
    "2.  **Random Forest:** Curiosamente, ponerle `class_weight='balanced'` a veces empeora las cosas. SMOTE parece sentarle mejor en general.\n",
    "3.  **No hay bala de plata:** Ninguna estrategia gana siempre. En el siguiente notebook (`modelos_avanzados`) me centrar茅 en afinar esto con XGBoost y pesos manuales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
