{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark de Estrategias en M√∫ltiples Datasets\n",
    "\n",
    "## Objetivo del Notebook\n",
    "\n",
    "Este notebook es un benchmark de alto nivel. Su objetivo es comparar el rendimiento de tres estrategias fundamentales para el manejo de datos desbalanceados, aplicadas a cuatro datasets de cr√©dito y fraude.\n",
    "\n",
    "**Estrategias a Comparar:**\n",
    "1.  **Estrategia 1: Convencional** (L√≠nea Base).\n",
    "2.  **Estrategia 2: Coste Sensible Fijo** (Usando `class_weight='balanced'`).\n",
    "3.  **Estrategia 3: Balanceo de Datos** (Usando `SMOTE`).\n",
    "\n",
    "**M√©tricas Clave:**\n",
    "* **`Balanced Accuracy`:** Mide el equilibrio general del modelo.\n",
    "* **`F1-Score (Clase Minoritaria)`:** Mide la efectividad (equilibrio Precisi√≥n/Recall) para detectar la clase \"Mal Riesgo\" o \"Fraude\", que es nuestro objetivo principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos a comparar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline # Renombrado para evitar conflicto\n",
    "\n",
    "# M√©tricas de evaluaci√≥n\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Para mostrar la tabla final\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definici√≥n de Modelos a Probar\n",
    "\n",
    "Se seleccionan tres tipos de modelos representativos: Regresi√≥n Log√≠stica (lineal), √Årbol de Decisi√≥n (√°rbol simple) y Random Forest (ensamble de √°rboles).\n",
    "\n",
    "**Nota sobre SVC (Support Vector Classifier):**\n",
    "Aunque `SVC` fue importado en la celda anterior, se ha **comentado y excluido** de este benchmark (`models_to_test`).\n",
    "\n",
    "La raz√≥n es su **alto coste computacional**. El tiempo de entrenamiento de SVC escala de forma cuadr√°tica o c√∫bica ($O(n^2)$ a $O(n^3)$) con el n√∫mero de muestras. Ejecutarlo en datasets grandes como \"Credit Card Fraud\" (284k muestras) o \"Give Me Some Credit\" (150k muestras) bajo 3 estrategias diferentes (36* ejecuciones) har√≠a que el notebook tardara horas en completarse.\n",
    "\n",
    "El `SVC` s√≠ se analiza en profundidad en el notebook `deteccion_impago_german_credit_data.ipynb`, que utiliza un dataset m√°s peque√±o (1000 muestras) donde su coste es manejable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    #'SVC': SVC(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Funci√≥n de Evaluaci√≥n 1: El Benchmark Convencional\n",
    "\n",
    "La siguiente funci√≥n, `evaluate_models`, se encarga de establecer la **l√≠nea base (benchmark)**. Esta es la referencia \"ingenua\" contra la cual mediremos todas nuestras estrategias.\n",
    "\n",
    "**¬øQu√© hace esta funci√≥n?**\n",
    "1.  **Recibe** un dataset (`X`, `y`), un diccionario de modelos (`models`) y un nombre (`dataset_name`).\n",
    "2.  **Preprocesa** los datos usando un `ColumnTransformer` est√°ndar (escala num√©ricos, codifica categ√≥ricos).\n",
    "3.  **Divide** los datos en entrenamiento y prueba (70/30) con estratificaci√≥n.\n",
    "4.  **Usa un `Pipeline` est√°ndar de scikit-learn**.\n",
    "5.  **Entrena** cada modelo (`LogisticRegression`, `RandomForest`, etc.) **sin ning√∫n par√°metro de coste** (ej. `class_weight=None`). Esto significa que el modelo trata todos los errores por igual.\n",
    "6.  **Eval√∫a** el rendimiento en el set de prueba usando `balanced_accuracy` y `f1_score`.\n",
    "7.  **Devuelve** una lista de resultados que se usar√° para construir la tabla \"Tipo 1: Convencional\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, models, dataset_name):\n",
    "    \"\"\"\n",
    "    Entrena y eval√∫a una lista de modelos en un dataset.\n",
    "    Devuelve una lista de diccionarios con los resultados de cada modelo.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluando Dataset: {dataset_name} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    # Preprocesamiento\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # Divisi√≥n de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    # Bucle para probar cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nProbando modelo: {model_name}...\")\n",
    "        \n",
    "        # Crear y entrenar el pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calcular y mostrar m√©tricas\n",
    "        print(\"Matriz de Confusi√≥n:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "        print(f\"F1-Score (clase 'mala'): {f1:.3f}\")\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results_list.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1_score_bad_class': f1\n",
    "        })\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen los 4 datasets a probar: German Credit, Taiwan Credit Default, Credit Card Fraud y Give Me Some Credit.\n",
    "\n",
    "Un paso clave en la carga de datos es **mapear la variable objetivo (y)** para que la **clase minoritaria (impago/fraude) sea siempre 1** y la mayoritaria sea 0. Esto estandariza la evaluaci√≥n.\n",
    "\n",
    "A continuaci√≥n, se ejecuta el benchmark convencional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO BENCHMARK (1. CONVENCIONAL)\n",
      "\n",
      "--- Cargando y procesando dataset: German Credit ---\n",
      "Mapeando: 'good' (Mayoritaria) -> 0, 'bad' (Minoritaria) -> 1\n",
      "--- Evaluando Dataset: German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi√≥n:\n",
      "[[187  23]\n",
      " [ 42  48]]\n",
      "Balanced Accuracy: 0.712\n",
      "F1-Score (clase 'mala'): 0.596\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi√≥n:\n",
      "[[196  14]\n",
      " [ 55  35]]\n",
      "Balanced Accuracy: 0.661\n",
      "F1-Score (clase 'mala'): 0.504\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi√≥n:\n",
      "[[158  52]\n",
      " [ 51  39]]\n",
      "Balanced Accuracy: 0.593\n",
      "F1-Score (clase 'mala'): 0.431\n",
      "Evaluaci√≥n convencional para German Credit completada.\n",
      "\n",
      "--- Cargando y procesando dataset: Taiwan Credit Default ---\n",
      "Mapeando: '0' (Mayoritaria) -> 0, '1' (Minoritaria) -> 1\n",
      "--- Evaluando Dataset: Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi√≥n:\n",
      "[[6805  204]\n",
      " [1521  470]]\n",
      "Balanced Accuracy: 0.603\n",
      "F1-Score (clase 'mala'): 0.353\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi√≥n:\n",
      "[[6598  411]\n",
      " [1270  721]]\n",
      "Balanced Accuracy: 0.652\n",
      "F1-Score (clase 'mala'): 0.462\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi√≥n:\n",
      "[[5710 1299]\n",
      " [1188  803]]\n",
      "Balanced Accuracy: 0.609\n",
      "F1-Score (clase 'mala'): 0.392\n",
      "Evaluaci√≥n convencional para Taiwan Credit Default completada.\n",
      "\n",
      "--- Cargando y procesando dataset: Credit Card Fraud ---\n",
      "Mapeando: '0' (Mayoritaria) -> 0, '1' (Minoritaria) -> 1\n",
      "--- Evaluando Dataset: Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85280    15]\n",
      " [   57    91]]\n",
      "Balanced Accuracy: 0.807\n",
      "F1-Score (clase 'mala'): 0.717\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85290     5]\n",
      " [   35   113]]\n",
      "Balanced Accuracy: 0.882\n",
      "F1-Score (clase 'mala'): 0.850\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85269    26]\n",
      " [   39   109]]\n",
      "Balanced Accuracy: 0.868\n",
      "F1-Score (clase 'mala'): 0.770\n",
      "Evaluaci√≥n convencional para Credit Card Fraud completada.\n",
      "\n",
      "--- Cargando y procesando dataset: Give Me Some Credit ---\n",
      "--- Evaluando Dataset: Give Me Some Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi√≥n:\n",
      "[[41898    94]\n",
      " [ 2883   125]]\n",
      "Balanced Accuracy: 0.520\n",
      "F1-Score (clase 'mala'): 0.077\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi√≥n:\n",
      "[[41555   437]\n",
      " [ 2453   555]]\n",
      "Balanced Accuracy: 0.587\n",
      "F1-Score (clase 'mala'): 0.278\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi√≥n:\n",
      "[[39631  2361]\n",
      " [ 2147   861]]\n",
      "Balanced Accuracy: 0.615\n",
      "F1-Score (clase 'mala'): 0.276\n",
      "Evaluaci√≥n convencional para Give Me Some Credit completada.\n",
      "\n",
      "‚úÖ --- TABLA COMPARATIVA (1. Convencional) --- ‚úÖ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>0.276404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519659</td>\n",
       "      <td>0.077471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.651745</td>\n",
       "      <td>0.461736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.608991</td>\n",
       "      <td>0.392377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.603478</td>\n",
       "      <td>0.352720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "7       Credit Card Fraud        Random Forest           0.881727  \\\n",
       "8       Credit Card Fraud        Decision Tree           0.868091   \n",
       "6       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "2           German Credit        Decision Tree           0.592857   \n",
       "11    Give Me Some Credit        Decision Tree           0.615006   \n",
       "10    Give Me Some Credit        Random Forest           0.587051   \n",
       "9     Give Me Some Credit  Logistic Regression           0.519659   \n",
       "4   Taiwan Credit Default        Random Forest           0.651745   \n",
       "5   Taiwan Credit Default        Decision Tree           0.608991   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.603478   \n",
       "\n",
       "    f1_score_bad_class  \n",
       "7             0.849624  \n",
       "8             0.770318  \n",
       "6             0.716535  \n",
       "0             0.596273  \n",
       "1             0.503597  \n",
       "2             0.430939  \n",
       "11            0.276404  \n",
       "10            0.277500  \n",
       "9             0.077471  \n",
       "4             0.461736  \n",
       "5             0.392377  \n",
       "3             0.352720  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Benchmark Convencional (Tarea 1) ---\n",
    "\n",
    "# Diccionario de datasets (con \"Give Me Some Credit\" activado)\n",
    "datasets_to_test = {\n",
    "    'German Credit': {'source': 'openml', 'id': 31, 'target_col': 'class'},\n",
    "    'Taiwan Credit Default': {'source': 'openml', 'id': 42477, 'target_col': 'class'},\n",
    "    'Credit Card Fraud': {'source': 'openml', 'id': 1597, 'target_col': 'class'},\n",
    "    'Give Me Some Credit': {'source': 'csv', 'path': '../data/cs-training.csv', 'target_col': 'SeriousDlqin2yrs'}\n",
    "}\n",
    "\n",
    "# Lista para guardar los resultados convencionales\n",
    "all_results_conv = []\n",
    "\n",
    "print(\"üöÄ INICIANDO BENCHMARK (1. CONVENCIONAL)\")\n",
    "\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        print(f\"\\n--- Cargando y procesando dataset: {name} ---\")\n",
    "        \n",
    "        if info['source'] == 'openml':\n",
    "            data = fetch_openml(data_id=info['id'], as_frame=True, parser='auto')\n",
    "            X = data.data\n",
    "            y_raw = data.target if 'target' in data else data['class']\n",
    "\n",
    "            # Mapeamos expl√≠citamente para que la clase MINORITARIA (fraude/default) sea 1\n",
    "            y_str = y_raw.astype(str)\n",
    "            counts = y_str.value_counts()\n",
    "\n",
    "            if len(counts) > 2:\n",
    "                print(f\"Advertencia: El dataset {name} tiene m√°s de 2 clases.\")\n",
    "                # L√≥gica simple para este caso: usar factorize\n",
    "                y = pd.Series(pd.factorize(y_raw)[0], index=y_raw.index)\n",
    "            else:\n",
    "                minority_label = counts.idxmin()\n",
    "                majority_label = counts.idxmax()\n",
    "                \n",
    "                print(f\"Mapeando: '{majority_label}' (Mayoritaria) -> 0, '{minority_label}' (Minoritaria) -> 1\")\n",
    "                y = y_str.map({majority_label: 0, minority_label: 1}).astype(int)\n",
    "                y.index = y_raw.index # Preservar el √≠ndice\n",
    "\n",
    "\n",
    "        elif info['source'] == 'csv':\n",
    "            df = pd.read_csv(info['path'])\n",
    "            # Asumimos que la primera columna (Unnamed: 0) es un √≠ndice y la quitamos\n",
    "            if 'Unnamed: 0' in df.columns:\n",
    "                df = df.drop(columns=['Unnamed: 0'])\n",
    "            X = df.drop(columns=[info['target_col']])\n",
    "            y_raw = df[info['target_col']]\n",
    "            \n",
    "            # El dataset CSV tiene valores nulos, los rellenamos con la media (estrategia simple)\n",
    "            X = X.fillna(X.mean())\n",
    "\n",
    "            # Este dataset ya es 0 (bueno) y 1 (malo). \n",
    "            # No usamos factorize, solo aseguramos que sea 'int'.\n",
    "            y = y_raw.astype(int)\n",
    "\n",
    "        \n",
    "        # Guardar los datos para las siguientes ejecuciones\n",
    "        info['X_data'] = X\n",
    "        info['y_data'] = y\n",
    "\n",
    "        # Llamar a la funci√≥n de evaluaci√≥n CONVENCIONAL (celda [5])\n",
    "        results = evaluate_models(X, y, models_to_test, name)\n",
    "        all_results_conv.extend(results)\n",
    "        print(f\"Evaluaci√≥n convencional para {name} completada.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üö® No se pudo procesar el dataset {name}. Error: {e}\")\n",
    "\n",
    "# Crear el DataFrame de resultados (esto reemplaza tu celda [7])\n",
    "final_results_conv_df = pd.DataFrame(all_results_conv)\n",
    "print(\"\\n‚úÖ --- TABLA COMPARATIVA (1. Convencional) --- ‚úÖ\")\n",
    "display(final_results_conv_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Resultados del Benchmark Convencional\n",
    "\n",
    "La tabla de resultados y la de promedios demuestran el problema central:\n",
    "\n",
    "* **Fracaso Total en Desbalanceo Extremo:** En \"Give Me Some Credit\" (6.7% de impagos), la Regresi√≥n Log√≠stica convencional obtiene un **F1-Score de 0.077**. Esto es un fracaso total: el modelo no tiene ninguna capacidad real de detectar impagos.\n",
    "* **Precisi√≥n Enga√±osa:** En \"Credit Card Fraud\" (0.17% de fraude), los modelos convencionales (especialmente RF y DT) obtienen un `Balanced Accuracy` y un `F1-Score` altos (ej. RF F1-Score 0.850). Esto se debe a que el conjunto de prueba es muy peque√±o y los modelos \"tuvieron suerte\", pero esta m√©trica es enga√±osa, como veremos.\n",
    "* **L√≠nea Base Promedio:** En promedio, el Random Forest (Bal. Acc. 0.695) es el mejor modelo convencional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä --- RENDIMIENTO MEDIO POR MODELO CONVENCIONAL (TODOS LOS DATASETS) --- üìä\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.695409</td>\n",
       "      <td>0.523114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.671236</td>\n",
       "      <td>0.467510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.660597</td>\n",
       "      <td>0.435750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     balanced_accuracy  f1_score_bad_class\n",
       "model                                                     \n",
       "Random Forest                 0.695409            0.523114\n",
       "Decision Tree                 0.671236            0.467510\n",
       "Logistic Regression           0.660597            0.435750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 6: Calcular y mostrar el rendimiento medio de cada modelo\n",
    "print(\"üìä --- RENDIMIENTO MEDIO POR MODELO CONVENCIONAL (TODOS LOS DATASETS) --- üìä\")\n",
    "\n",
    "# Agrupamos por 'model' y calculamos la media de las m√©tricas\n",
    "average_performance = final_results_conv_df.groupby('model')[['balanced_accuracy', 'f1_score_bad_class']].mean()\n",
    "\n",
    "# Ordenamos por la m√©trica que consideremos m√°s importante para ver el ranking\n",
    "average_performance_sorted = average_performance.sort_values(by='balanced_accuracy', ascending=False)\n",
    "\n",
    "display(average_performance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funci√≥n de Evaluaci√≥n 2: Estrategia de Coste Sensible (CSL)\n",
    "\n",
    "La funci√≥n `evaluate_cost_sensitive_models` implementa la primera de nuestras estrategias avanzadas: el **Aprendizaje Sensible a Costes (CSL)** en su forma m√°s simple.\n",
    "\n",
    "**¬øQu√© hace esta funci√≥n?**\n",
    "* Es id√©ntica a la funci√≥n convencional, con **una diferencia clave**:\n",
    "* Al crear el `Pipeline`, re-inicializa cada modelo y le a√±ade expl√≠citamente el par√°metro **`class_weight='balanced'`**.\n",
    "\n",
    "**¬øQu√© significa `class_weight='balanced'`?**\n",
    "* Modifica la **funci√≥n de coste del algoritmo**.\n",
    "* Le dice al modelo que, durante el entrenamiento (`.fit()`), debe **penalizar m√°s los errores en la clase minoritaria** (impago/fraude) y menos los de la clase mayoritaria.\n",
    "* El peso de la penalizaci√≥n es inversamente proporcional a la frecuencia de la clase, equilibrando su \"importancia\".\n",
    "* Esto es un **cambio a nivel de algoritmo**, no a nivel de datos.\n",
    "* Los resultados de esta funci√≥n se usar√°n para la tabla \"Tipo 2: Coste Sensible\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report # Asegurarse de que classification_report est√° importado\n",
    "\n",
    "def evaluate_cost_sensitive_models(X, y, models, dataset_name):\n",
    "    \"\"\"\n",
    "    Versi√≥n de la funci√≥n de evaluaci√≥n que entrena los modelos\n",
    "    con sensibilidad al coste y MUESTRA los resultados detallados.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluando Dataset (Sensible a Costes): {dataset_name} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    # Mismo preprocesamiento y divisi√≥n que antes\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nProbando modelo: {model_name} (Sensible al Coste)...\")\n",
    "        \n",
    "        # Re-inicializamos el modelo con el par√°metro class_weight='balanced'\n",
    "        if model_name == 'Logistic Regression':\n",
    "            model_cs = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "        elif model_name == 'Random Forest':\n",
    "            model_cs = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "        elif model_name == 'SVC':\n",
    "            model_cs = SVC(random_state=42, class_weight='balanced')\n",
    "        elif model_name == 'Decision Tree':\n",
    "            model_cs = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model_cs)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # --- C√ìDIGO A√ëADIDO PARA MOSTRAR DETALLES ---\n",
    "        print(\"Matriz de Confusi√≥n:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "        print(f\"F1-Score (clase 'mala'): {f1:.3f}\")\n",
    "        print(\"Reporte de Clasificaci√≥n:\")\n",
    "        # Usamos try-except por si alguna predicci√≥n no tiene ambas clases\n",
    "        try:\n",
    "            target_names = [f'Clase {i}' for i in sorted(y.unique())]\n",
    "            print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "        except:\n",
    "            print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "        # --- FIN DEL C√ìDIGO A√ëADIDO ---\n",
    "\n",
    "        results_list.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1_score_bad_class': f1\n",
    "        })\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Funci√≥n de Evaluaci√≥n 3: Estrategia de Balanceo (SMOTE)\n",
    "\n",
    "La funci√≥n `evaluate_smote_models` implementa la segunda estrategia avanzada: el **Balanceo de Datos** usando la t√©cnica **SMOTE** (Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "**¬øQu√© hace esta funci√≥n?**\n",
    "* Esta funci√≥n tiene **dos diferencias clave** con la convencional:\n",
    "1.  Utiliza `ImbPipeline` (un pipeline de la librer√≠a `imblearn`) en lugar del `Pipeline` est√°ndar de `sklearn`.\n",
    "2.  A√±ade un nuevo paso al pipeline: `('smote', SMOTE(random_state=42))`.\n",
    "\n",
    "**¬øC√≥mo funciona?**\n",
    "* Esto es un **cambio a nivel de datos**.\n",
    "* Cuando se llama a `.fit()`, `ImbPipeline` primero aplica `SMOTE` **solo a los datos de entrenamiento (`X_train`)**. SMOTE crea \"muestras sint√©ticas\" de la clase minoritaria hasta que el dataset de entrenamiento queda balanceado.\n",
    "* Luego, el modelo (convencional, con `class_weight=None`) se entrena con este **nuevo set de datos balanceado**.\n",
    "* Es crucial que `SMOTE` no se aplica al `X_test` (para evitar fuga de datos), y el `ImbPipeline` maneja esto autom√°ticamente.\n",
    "* Los resultados de esta funci√≥n se usar√°n para la tabla \"Tipo 3: Balanceo (SMOTE)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.b. Funci√≥n de Evaluaci√≥n (Balanceo SMOTE) ---\n",
    "\n",
    "def evaluate_smote_models(X, y, models, dataset_name):\n",
    "    \"\"\"\n",
    "    Versi√≥n de la funci√≥n de evaluaci√≥n que entrena los modelos\n",
    "    con balanceo SMOTE (Tarea 3.8).\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluando Dataset (Balanceo SMOTE): {dataset_name} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    # Mismo preprocesamiento y divisi√≥n\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        # 1. Crear el pipeline de IMBLearn (¬°Importante!)\n",
    "        # SMOTE solo se aplica al .fit(), no al .predict()\n",
    "        pipeline_smote = ImbPipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('smote', SMOTE(random_state=42)), # 2. A√±adir SMOTE\n",
    "            ('classifier', model.set_params(class_weight=None)) # 3. Usar el modelo *convencional*\n",
    "        ])\n",
    "        \n",
    "        # Entrenar\n",
    "        pipeline_smote.fit(X_train, y_train)\n",
    "        y_pred = pipeline_smote.predict(X_test)\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0) # Asumimos 1 es la clase 'mala'\n",
    "\n",
    "        results_list.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1_score_bad_class': f1,\n",
    "            'Tipo': '3. Balanceo (SMOTE)' # A√±adimos el tipo\n",
    "        })\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ INICIANDO BENCHMARK (2. COSTE SENSIBLE)\n",
      "\n",
      "Procesando German Credit (Coste Sensible)...\n",
      "--- Evaluando Dataset (Sensible a Costes): German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[150  60]\n",
      " [ 21  69]]\n",
      "Balanced Accuracy: 0.740\n",
      "F1-Score (clase 'mala'): 0.630\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.88      0.71      0.79       210\n",
      "     Clase 1       0.53      0.77      0.63        90\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.71      0.74      0.71       300\n",
      "weighted avg       0.77      0.73      0.74       300\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[194  16]\n",
      " [ 61  29]]\n",
      "Balanced Accuracy: 0.623\n",
      "F1-Score (clase 'mala'): 0.430\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.76      0.92      0.83       210\n",
      "     Clase 1       0.64      0.32      0.43        90\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.70      0.62      0.63       300\n",
      "weighted avg       0.73      0.74      0.71       300\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[155  55]\n",
      " [ 50  40]]\n",
      "Balanced Accuracy: 0.591\n",
      "F1-Score (clase 'mala'): 0.432\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.76      0.74      0.75       210\n",
      "     Clase 1       0.42      0.44      0.43        90\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.59      0.59      0.59       300\n",
      "weighted avg       0.66      0.65      0.65       300\n",
      "\n",
      "Evaluaci√≥n CSL para German Credit completada.\n",
      "\n",
      "Procesando Taiwan Credit Default (Coste Sensible)...\n",
      "--- Evaluando Dataset (Sensible a Costes): Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[4903 2106]\n",
      " [ 740 1251]]\n",
      "Balanced Accuracy: 0.664\n",
      "F1-Score (clase 'mala'): 0.468\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.87      0.70      0.78      7009\n",
      "     Clase 1       0.37      0.63      0.47      1991\n",
      "\n",
      "    accuracy                           0.68      9000\n",
      "   macro avg       0.62      0.66      0.62      9000\n",
      "weighted avg       0.76      0.68      0.71      9000\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[6629  380]\n",
      " [1304  687]]\n",
      "Balanced Accuracy: 0.645\n",
      "F1-Score (clase 'mala'): 0.449\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.84      0.95      0.89      7009\n",
      "     Clase 1       0.64      0.35      0.45      1991\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.74      0.65      0.67      9000\n",
      "weighted avg       0.79      0.81      0.79      9000\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[5827 1182]\n",
      " [1185  806]]\n",
      "Balanced Accuracy: 0.618\n",
      "F1-Score (clase 'mala'): 0.405\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.83      0.83      0.83      7009\n",
      "     Clase 1       0.41      0.40      0.41      1991\n",
      "\n",
      "    accuracy                           0.74      9000\n",
      "   macro avg       0.62      0.62      0.62      9000\n",
      "weighted avg       0.74      0.74      0.74      9000\n",
      "\n",
      "Evaluaci√≥n CSL para Taiwan Credit Default completada.\n",
      "\n",
      "Procesando Credit Card Fraud (Coste Sensible)...\n",
      "--- Evaluando Dataset (Sensible a Costes): Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[83407  1888]\n",
      " [   19   129]]\n",
      "Balanced Accuracy: 0.925\n",
      "F1-Score (clase 'mala'): 0.119\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      0.98      0.99     85295\n",
      "     Clase 1       0.06      0.87      0.12       148\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.92      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85292     3]\n",
      " [   44   104]]\n",
      "Balanced Accuracy: 0.851\n",
      "F1-Score (clase 'mala'): 0.816\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.97      0.70      0.82       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.99      0.85      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85263    32]\n",
      " [   52    96]]\n",
      "Balanced Accuracy: 0.824\n",
      "F1-Score (clase 'mala'): 0.696\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.75      0.65      0.70       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.87      0.82      0.85     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "Evaluaci√≥n CSL para Credit Card Fraud completada.\n",
      "\n",
      "Procesando Give Me Some Credit (Coste Sensible)...\n",
      "--- Evaluando Dataset (Sensible a Costes): Give Me Some Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[32956  9036]\n",
      " [ 1026  1982]]\n",
      "Balanced Accuracy: 0.722\n",
      "F1-Score (clase 'mala'): 0.283\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.97      0.78      0.87     41992\n",
      "     Clase 1       0.18      0.66      0.28      3008\n",
      "\n",
      "    accuracy                           0.78     45000\n",
      "   macro avg       0.57      0.72      0.58     45000\n",
      "weighted avg       0.92      0.78      0.83     45000\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[41646   346]\n",
      " [ 2547   461]]\n",
      "Balanced Accuracy: 0.573\n",
      "F1-Score (clase 'mala'): 0.242\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.94      0.99      0.97     41992\n",
      "     Clase 1       0.57      0.15      0.24      3008\n",
      "\n",
      "    accuracy                           0.94     45000\n",
      "   macro avg       0.76      0.57      0.60     45000\n",
      "weighted avg       0.92      0.94      0.92     45000\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[39831  2161]\n",
      " [ 2262   746]]\n",
      "Balanced Accuracy: 0.598\n",
      "F1-Score (clase 'mala'): 0.252\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.95      0.95      0.95     41992\n",
      "     Clase 1       0.26      0.25      0.25      3008\n",
      "\n",
      "    accuracy                           0.90     45000\n",
      "   macro avg       0.60      0.60      0.60     45000\n",
      "weighted avg       0.90      0.90      0.90     45000\n",
      "\n",
      "Evaluaci√≥n CSL para Give Me Some Credit completada.\n",
      "\n",
      "‚úÖ --- TABLA COMPARATIVA (2. Coste Sensible) --- ‚úÖ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.924743</td>\n",
       "      <td>0.119169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.851334</td>\n",
       "      <td>0.815686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.824137</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.630137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.429630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721863</td>\n",
       "      <td>0.282618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.598272</td>\n",
       "      <td>0.252240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.572509</td>\n",
       "      <td>0.241678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.663928</td>\n",
       "      <td>0.467838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.645418</td>\n",
       "      <td>0.449313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.618091</td>\n",
       "      <td>0.405127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "6       Credit Card Fraud  Logistic Regression           0.924743  \\\n",
       "7       Credit Card Fraud        Random Forest           0.851334   \n",
       "8       Credit Card Fraud        Decision Tree           0.824137   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "1           German Credit        Random Forest           0.623016   \n",
       "2           German Credit        Decision Tree           0.591270   \n",
       "9     Give Me Some Credit  Logistic Regression           0.721863   \n",
       "11    Give Me Some Credit        Decision Tree           0.598272   \n",
       "10    Give Me Some Credit        Random Forest           0.572509   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.663928   \n",
       "4   Taiwan Credit Default        Random Forest           0.645418   \n",
       "5   Taiwan Credit Default        Decision Tree           0.618091   \n",
       "\n",
       "    f1_score_bad_class  \n",
       "6             0.119169  \n",
       "7             0.815686  \n",
       "8             0.695652  \n",
       "0             0.630137  \n",
       "1             0.429630  \n",
       "2             0.432432  \n",
       "9             0.282618  \n",
       "11            0.252240  \n",
       "10            0.241678  \n",
       "3             0.467838  \n",
       "4             0.449313  \n",
       "5             0.405127  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 2. Benchmark (Coste Sensible 'balanced') ---\n",
    "\n",
    "all_results_cs = []\n",
    "\n",
    "print(\"\\nüöÄ INICIANDO BENCHMARK (2. COSTE SENSIBLE)\")\n",
    "\n",
    "# Este bucle ahora REUTILIZA los datos X e y cargados en la celda [6]\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        if 'X_data' in info: # Solo si se carg√≥ correctamente antes\n",
    "            print(f\"\\nProcesando {name} (Coste Sensible)...\")\n",
    "            \n",
    "            # Usamos los datos limpios y guardados\n",
    "            X = info['X_data']\n",
    "            y = info['y_data']\n",
    "            \n",
    "            # Llamar a la funci√≥n de evaluaci√≥n de COSTE SENSIBLE (celda [9])\n",
    "            results_cs = evaluate_cost_sensitive_models(X, y, models_to_test, name)\n",
    "            all_results_cs.extend(results_cs)\n",
    "            print(f\"Evaluaci√≥n CSL para {name} completada.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Saltando {name} (no se cargaron los datos en el paso anterior).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üö® No se pudo procesar el dataset {name} (CSL). Error: {e}\")\n",
    "\n",
    "final_results_cs_df = pd.DataFrame(all_results_cs)\n",
    "print(\"\\n‚úÖ --- TABLA COMPARATIVA (2. Coste Sensible) --- ‚úÖ\")\n",
    "display(final_results_cs_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Resultados del Benchmark CSL (`class_weight='balanced'`)\n",
    "\n",
    "Los resultados de CSL revelan un patr√≥n fundamental:\n",
    "\n",
    "* **Mejora en Desbalanceo Moderado:** En \"Give Me Some Credit\" (6.7%), el CSL mejora dr√°sticamente el F1-Score de la Regresi√≥n Log√≠stica (de 0.077 a **0.283**).\n",
    "* **Fracaso en Desbalanceo Extremo:** En \"Credit Card Fraud\" (0.17%), el CSL (`'balanced'`) es **desastroso**. El F1-Score de la Regresi√≥n Log√≠stica colapsa de 0.717 (convencional) a **0.119**.\n",
    "* **Fallo en Random Forest:** La `Balanced Accuracy` promedio de RF *empeora* (de 0.695 a 0.673).\n",
    "\n",
    "**Conclusi√≥n clave:** `class_weight='balanced'` funciona para modelos lineales en desbalanceo *moderado*, pero **falla estrepitosamente** en desbalanceo *extremo* (colapsa el F1-Score) y no funciona bien con Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä --- RENDIMIENTO MEDIO POR MODELO COSTE (TODOS LOS DATASETS) --- üìä\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.762753</td>\n",
       "      <td>0.374941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.673069</td>\n",
       "      <td>0.484077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.657942</td>\n",
       "      <td>0.446363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     balanced_accuracy  f1_score_bad_class\n",
       "model                                                     \n",
       "Logistic Regression           0.762753            0.374941\n",
       "Random Forest                 0.673069            0.484077\n",
       "Decision Tree                 0.657942            0.446363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 6: Calcular y mostrar el rendimiento medio de cada modelo\n",
    "print(\"üìä --- RENDIMIENTO MEDIO POR MODELO COSTE (TODOS LOS DATASETS) --- üìä\")\n",
    "\n",
    "# Agrupamos por 'model' y calculamos la media de las m√©tricas\n",
    "average_performance = final_results_cs_df.groupby('model')[['balanced_accuracy', 'f1_score_bad_class']].mean()\n",
    "\n",
    "# Ordenamos por la m√©trica que consideremos m√°s importante para ver el ranking\n",
    "average_performance_sorted = average_performance.sort_values(by='balanced_accuracy', ascending=False)\n",
    "\n",
    "display(average_performance_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ INICIANDO BENCHMARK (3. BALANCEO SMOTE)\n",
      "\n",
      "Procesando German Credit (SMOTE)...\n",
      "--- Evaluando Dataset (Balanceo SMOTE): German Credit ---\n",
      "Evaluaci√≥n SMOTE para German Credit completada.\n",
      "\n",
      "Procesando Taiwan Credit Default (SMOTE)...\n",
      "--- Evaluando Dataset (Balanceo SMOTE): Taiwan Credit Default ---\n",
      "Evaluaci√≥n SMOTE para Taiwan Credit Default completada.\n",
      "\n",
      "Procesando Credit Card Fraud (SMOTE)...\n",
      "--- Evaluando Dataset (Balanceo SMOTE): Credit Card Fraud ---\n",
      "Evaluaci√≥n SMOTE para Credit Card Fraud completada.\n",
      "\n",
      "Procesando Give Me Some Credit (SMOTE)...\n",
      "--- Evaluando Dataset (Balanceo SMOTE): Give Me Some Credit ---\n",
      "Evaluaci√≥n SMOTE para Give Me Some Credit completada.\n",
      "\n",
      "‚úÖ --- TABLA COMPARATIVA (3. Balanceo SMOTE) --- ‚úÖ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.930873</td>\n",
       "      <td>0.115215</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.891804</td>\n",
       "      <td>0.831541</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.522876</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.716450</td>\n",
       "      <td>0.268322</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.648427</td>\n",
       "      <td>0.353884</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.622387</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.675323</td>\n",
       "      <td>0.498507</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.660108</td>\n",
       "      <td>0.462825</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.616881</td>\n",
       "      <td>0.408244</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "6       Credit Card Fraud  Logistic Regression           0.930873  \\\n",
       "7       Credit Card Fraud        Random Forest           0.891804   \n",
       "8       Credit Card Fraud        Decision Tree           0.873927   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "1           German Credit        Random Forest           0.667460   \n",
       "2           German Credit        Decision Tree           0.580952   \n",
       "9     Give Me Some Credit  Logistic Regression           0.716450   \n",
       "10    Give Me Some Credit        Random Forest           0.648427   \n",
       "11    Give Me Some Credit        Decision Tree           0.622387   \n",
       "4   Taiwan Credit Default        Random Forest           0.675323   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.660108   \n",
       "5   Taiwan Credit Default        Decision Tree           0.616881   \n",
       "\n",
       "    f1_score_bad_class                 Tipo  \n",
       "6             0.115215  3. Balanceo (SMOTE)  \n",
       "7             0.831541  3. Balanceo (SMOTE)  \n",
       "8             0.502262  3. Balanceo (SMOTE)  \n",
       "0             0.631579  3. Balanceo (SMOTE)  \n",
       "1             0.522876  3. Balanceo (SMOTE)  \n",
       "2             0.409091  3. Balanceo (SMOTE)  \n",
       "9             0.268322  3. Balanceo (SMOTE)  \n",
       "10            0.353884  3. Balanceo (SMOTE)  \n",
       "11            0.250965  3. Balanceo (SMOTE)  \n",
       "4             0.498507  3. Balanceo (SMOTE)  \n",
       "3             0.462825  3. Balanceo (SMOTE)  \n",
       "5             0.408244  3. Balanceo (SMOTE)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3. Benchmark (Balanceo SMOTE) ---\n",
    "\n",
    "all_results_smote = []\n",
    "\n",
    "print(\"\\nüöÄ INICIANDO BENCHMARK (3. BALANCEO SMOTE)\")\n",
    "\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        if 'X_data' in info: \n",
    "            print(f\"\\nProcesando {name} (SMOTE)...\")\n",
    "            X = info['X_data']\n",
    "            y = info['y_data']\n",
    "            \n",
    "            results_smote = evaluate_smote_models(X, y, models_to_test, name)\n",
    "            all_results_smote.extend(results_smote)\n",
    "            print(f\"Evaluaci√≥n SMOTE para {name} completada.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Saltando {name} (no se cargaron los datos).\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"üö® No se pudo procesar el dataset {name} (SMOTE). Error: {e}\")\n",
    "\n",
    "final_results_smote_df = pd.DataFrame(all_results_smote)\n",
    "print(\"\\n‚úÖ --- TABLA COMPARATIVA (3. Balanceo SMOTE) --- ‚úÖ\")\n",
    "display(final_results_smote_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Resultados del Benchmark SMOTE\n",
    "\n",
    "Los resultados de SMOTE (visibles en la tabla de la celda 13) muestran un patr√≥n diferente:\n",
    "\n",
    "* **√âxito en Regresi√≥n Log√≠stica:** Al igual que CSL, SMOTE **mejora dr√°sticamente** el rendimiento de LR (promedio de 0.661 a 0.762).\n",
    "* **√âxito en Random Forest:** A diferencia de CSL, SMOTE **s√≠ mejora** el rendimiento de RF (promedio de 0.695 a 0.720).\n",
    "\n",
    "Esto sugiere que los modelos de Random Forest se benefician m√°s de ver un conjunto de datos balanceado (SMOTE) que de una penalizaci√≥n interna (CSL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä --- TABLA COMPARATIVA FINAL: ESTRATEGIAS vs. DATASETS --- üìä\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.824137</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.924743</td>\n",
       "      <td>0.119169</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.930873</td>\n",
       "      <td>0.115215</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.851334</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.891804</td>\n",
       "      <td>0.831541</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.522876</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>0.276404</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.598272</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.622387</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519659</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721863</td>\n",
       "      <td>0.282618</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.716450</td>\n",
       "      <td>0.268322</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.572509</td>\n",
       "      <td>0.241678</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.648427</td>\n",
       "      <td>0.353884</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.608991</td>\n",
       "      <td>0.392377</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.618091</td>\n",
       "      <td>0.405127</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.616881</td>\n",
       "      <td>0.408244</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.603478</td>\n",
       "      <td>0.352720</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.663928</td>\n",
       "      <td>0.467838</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.660108</td>\n",
       "      <td>0.462825</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.651745</td>\n",
       "      <td>0.461736</td>\n",
       "      <td>1. Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.645418</td>\n",
       "      <td>0.449313</td>\n",
       "      <td>2. Coste Sensible (class_weight)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.675323</td>\n",
       "      <td>0.498507</td>\n",
       "      <td>3. Balanceo (SMOTE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "8       Credit Card Fraud        Decision Tree           0.868091  \\\n",
       "8       Credit Card Fraud        Decision Tree           0.824137   \n",
       "8       Credit Card Fraud        Decision Tree           0.873927   \n",
       "6       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "6       Credit Card Fraud  Logistic Regression           0.924743   \n",
       "6       Credit Card Fraud  Logistic Regression           0.930873   \n",
       "7       Credit Card Fraud        Random Forest           0.881727   \n",
       "7       Credit Card Fraud        Random Forest           0.851334   \n",
       "7       Credit Card Fraud        Random Forest           0.891804   \n",
       "2           German Credit        Decision Tree           0.592857   \n",
       "2           German Credit        Decision Tree           0.591270   \n",
       "2           German Credit        Decision Tree           0.580952   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "1           German Credit        Random Forest           0.623016   \n",
       "1           German Credit        Random Forest           0.667460   \n",
       "11    Give Me Some Credit        Decision Tree           0.615006   \n",
       "11    Give Me Some Credit        Decision Tree           0.598272   \n",
       "11    Give Me Some Credit        Decision Tree           0.622387   \n",
       "9     Give Me Some Credit  Logistic Regression           0.519659   \n",
       "9     Give Me Some Credit  Logistic Regression           0.721863   \n",
       "9     Give Me Some Credit  Logistic Regression           0.716450   \n",
       "10    Give Me Some Credit        Random Forest           0.587051   \n",
       "10    Give Me Some Credit        Random Forest           0.572509   \n",
       "10    Give Me Some Credit        Random Forest           0.648427   \n",
       "5   Taiwan Credit Default        Decision Tree           0.608991   \n",
       "5   Taiwan Credit Default        Decision Tree           0.618091   \n",
       "5   Taiwan Credit Default        Decision Tree           0.616881   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.603478   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.663928   \n",
       "3   Taiwan Credit Default  Logistic Regression           0.660108   \n",
       "4   Taiwan Credit Default        Random Forest           0.651745   \n",
       "4   Taiwan Credit Default        Random Forest           0.645418   \n",
       "4   Taiwan Credit Default        Random Forest           0.675323   \n",
       "\n",
       "    f1_score_bad_class                              Tipo  \n",
       "8             0.770318                   1. Convencional  \n",
       "8             0.695652  2. Coste Sensible (class_weight)  \n",
       "8             0.502262               3. Balanceo (SMOTE)  \n",
       "6             0.716535                   1. Convencional  \n",
       "6             0.119169  2. Coste Sensible (class_weight)  \n",
       "6             0.115215               3. Balanceo (SMOTE)  \n",
       "7             0.849624                   1. Convencional  \n",
       "7             0.815686  2. Coste Sensible (class_weight)  \n",
       "7             0.831541               3. Balanceo (SMOTE)  \n",
       "2             0.430939                   1. Convencional  \n",
       "2             0.432432  2. Coste Sensible (class_weight)  \n",
       "2             0.409091               3. Balanceo (SMOTE)  \n",
       "0             0.596273                   1. Convencional  \n",
       "0             0.630137  2. Coste Sensible (class_weight)  \n",
       "0             0.631579               3. Balanceo (SMOTE)  \n",
       "1             0.503597                   1. Convencional  \n",
       "1             0.429630  2. Coste Sensible (class_weight)  \n",
       "1             0.522876               3. Balanceo (SMOTE)  \n",
       "11            0.276404                   1. Convencional  \n",
       "11            0.252240  2. Coste Sensible (class_weight)  \n",
       "11            0.250965               3. Balanceo (SMOTE)  \n",
       "9             0.077471                   1. Convencional  \n",
       "9             0.282618  2. Coste Sensible (class_weight)  \n",
       "9             0.268322               3. Balanceo (SMOTE)  \n",
       "10            0.277500                   1. Convencional  \n",
       "10            0.241678  2. Coste Sensible (class_weight)  \n",
       "10            0.353884               3. Balanceo (SMOTE)  \n",
       "5             0.392377                   1. Convencional  \n",
       "5             0.405127  2. Coste Sensible (class_weight)  \n",
       "5             0.408244               3. Balanceo (SMOTE)  \n",
       "3             0.352720                   1. Convencional  \n",
       "3             0.467838  2. Coste Sensible (class_weight)  \n",
       "3             0.462825               3. Balanceo (SMOTE)  \n",
       "4             0.461736                   1. Convencional  \n",
       "4             0.449313  2. Coste Sensible (class_weight)  \n",
       "4             0.498507               3. Balanceo (SMOTE)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- TABLA COMPARATIVA FINAL (TAREA 7) ---\n",
    "\n",
    "# A√±adimos una columna 'Tipo' para diferenciar los resultados\n",
    "final_results_conv_df['Tipo'] = '1. Convencional'\n",
    "final_results_cs_df['Tipo'] = '2. Coste Sensible (class_weight)'\n",
    "final_results_smote_df['Tipo'] = '3. Balanceo (SMOTE)' \n",
    "\n",
    "# Unimos las TRES tablas de resultados\n",
    "comparison_df = pd.concat([final_results_conv_df, final_results_cs_df, final_results_smote_df]) \n",
    "\n",
    "# Mostramos la tabla final, ordenada para facilitar la comparaci√≥n\n",
    "print(\"üìä --- TABLA COMPARATIVA FINAL: ESTRATEGIAS vs. DATASETS --- üìä\")\n",
    "display(comparison_df.sort_values(by=['dataset', 'model', 'Tipo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusiones Finales del Benchmark\n",
    "\n",
    "La tabla comparativa final consolida los hallazgos:\n",
    "\n",
    "1.  **Para Regresi√≥n Log√≠stica (Lineal):**\n",
    "    * En desbalanceo **moderado** (\"German Credit\", \"Taiwan\"), tanto **CSL (`'balanced'`)** como **SMOTE** son estrategias excelentes y muy similares, mejorando tanto `Balanced Accuracy` como `F1-Score` (ej. German F1-Score: 0.596 -> **0.630**).\n",
    "    * En desbalanceo **extremo** (\"Credit Card Fraud\"), ambas estrategias **fallan**, colapsando el `F1-Score` (0.717 -> **0.119** con CSL y **0.115** con SMOTE).\n",
    "\n",
    "2.  **Para Random Forest (Bagging):**\n",
    "    * **SMOTE** es la estrategia ganadora en promedio (mejora F1 de 0.523 a 0.552).\n",
    "    * **CSL (`'balanced'`)** es una mala estrategia; empeora tanto la `Balanced Accuracy` como el `F1-Score` en promedio.\n",
    "\n",
    "**Conclusi√≥n General:** Este notebook justifica la necesidad de estrategias m√°s avanzadas. `class_weight='balanced'` y `SMOTE` (con par√°metros por defecto) no son soluciones universales y **fallan en los casos de desbalanceo extremo**, que es donde se centra el notebook `modelos_avanzados.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
