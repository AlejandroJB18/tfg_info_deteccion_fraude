{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c270c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Añadir el directorio 'src' al path para poder importar los módulos\n",
    "# Asumiendo que el notebook está en la carpeta 'notebooks/' o 'exploracion/'\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "# Importar tus módulos\n",
    "import load_data\n",
    "import train_model\n",
    "import explicabilidad  # Este es tu nuevo fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd4a768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "Loaded 284,807 transactions from credit_card.csv\n",
      "Fraud rate: 0.17275%\n",
      "Total fraud amount: $60,127.97\n",
      "Datos cargados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Ruta a tu dataset\n",
    "# Ajusta esto según dónde tengas tu CSV, por ejemplo: '../data/creditcard.csv'\n",
    "csv_path = '../data/credit_card.csv' \n",
    "\n",
    "try:\n",
    "    print(\"Cargando datos...\")\n",
    "    # Usamos tu función existente para cargar y separar X e y\n",
    "    df, X, y = load_data.load_fraud_csv(csv_path)\n",
    "    \n",
    "    # Separamos el 'Amount' para el entrenamiento con costes (como haces en train_model.py)\n",
    "    amount_train = X['Amount'] \n",
    "    \n",
    "    print(\"Datos cargados correctamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: No se encontró el archivo en {csv_path}. Verifica la ruta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d0ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: (199364, 29), Test: (85443, 29)\n"
     ]
    }
   ],
   "source": [
    "# División estratificada (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Recuperamos la columna 'Amount' correspondiente a los índices de train\n",
    "amount_train_split = X.loc[X_train.index, 'Amount']\n",
    "\n",
    "print(f\"Entrenamiento: {X_train.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46740ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo XGBoost con coste sensible...\n",
      "XGBoost trained (factor=20)\n",
      "Modelo entrenado.\n"
     ]
    }
   ],
   "source": [
    "print(\"Entrenando modelo XGBoost con coste sensible...\")\n",
    "\n",
    "model = train_model.train_xgb_with_cost(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    amount_train_split, \n",
    "    amount_factor=20\n",
    ")\n",
    "\n",
    "print(\"Modelo entrenado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c79e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando explicador SHAP...\n"
     ]
    },
    {
     "ename": "InvalidModelError",
     "evalue": "Model type not yet supported by TreeExplainer: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidModelError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInicializando explicador SHAP...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Llamamos a la función de tu nuevo archivo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m explainer = \u001b[43mexplicabilidad\u001b[49m\u001b[43m.\u001b[49m\u001b[43miniciar_explainer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../models/models/fraud_detection_xgboost_final.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExplicador listo.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Uni/tfg_info_deteccion_fraude/src/explicabilidad.py:13\u001b[39m, in \u001b[36miniciar_explainer\u001b[39m\u001b[34m(model, X_train)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03mInicializa el explicador SHAP optimizado para árboles.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Para XGBoost, LightGBM y RandomForest usamos TreeExplainer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m explainer = \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTreeExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m explainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:175\u001b[39m, in \u001b[36mTreeExplainer.__init__\u001b[39m\u001b[34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_perturbation = feature_perturbation\n\u001b[32m    174\u001b[39m \u001b[38;5;28mself\u001b[39m.expected_value = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mTreeEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28mself\u001b[39m.model_output = model_output\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/shap/explainers/_tree.py:1226\u001b[39m, in \u001b[36mTreeEnsemble.__init__\u001b[39m\u001b[34m(self, model, data, data_missing, model_output)\u001b[39m\n\u001b[32m   1224\u001b[39m     \u001b[38;5;28mself\u001b[39m.base_offset = model.init_params[param_idx]\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidModelError(\u001b[33m\"\u001b[39m\u001b[33mModel type not yet supported by TreeExplainer: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model)))\n\u001b[32m   1228\u001b[39m \u001b[38;5;66;03m# build a dense numpy version of all the tree objects\u001b[39;00m\n\u001b[32m   1229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trees \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trees:\n",
      "\u001b[31mInvalidModelError\u001b[39m: Model type not yet supported by TreeExplainer: <class 'str'>"
     ]
    }
   ],
   "source": [
    "print(\"Inicializando explicador SHAP...\")\n",
    "# Llamamos a la función de tu nuevo archivo\n",
    "explainer = explicabilidad.iniciar_explainer(model, X_train)\n",
    "print(\"Explicador listo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd7e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando explicación global del modelo...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'explainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Usamos una muestra del test para agilizar el cálculo si el dataset es muy grande\u001b[39;00m\n\u001b[32m      3\u001b[39m X_test_sample = X_test.sample(\u001b[32m1000\u001b[39m, random_state=\u001b[32m42\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_test) > \u001b[32m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X_test\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m explicabilidad.explicar_global(\u001b[43mexplainer\u001b[49m, X_test_sample)\n",
      "\u001b[31mNameError\u001b[39m: name 'explainer' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Generando explicación global del modelo...\")\n",
    "# Usamos una muestra del test para agilizar el cálculo si el dataset es muy grande\n",
    "X_test_sample = X_test.sample(1000, random_state=42) if len(X_test) > 1000 else X_test\n",
    "\n",
    "explicabilidad.explicar_global(explainer, X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Buscamos un caso real de fraude en el set de prueba para explicarlo\n",
    "# Filtramos los índices donde la etiqueta real es 1 (Fraude)\n",
    "indices_fraude = y_test[y_test == 1].index\n",
    "\n",
    "if len(indices_fraude) > 0:\n",
    "    # Tomamos el primer fraude encontrado\n",
    "    id_fraude_real = indices_fraude[0]\n",
    "    \n",
    "    # Necesitamos la posición numérica (iloc) de este índice en X_test para pasárselo a tu función\n",
    "    posicion_en_test = X_test.index.get_loc(id_fraude_real)\n",
    "    \n",
    "    print(f\"Analizando transacción fraudulenta (Índice original: {id_fraude_real})\")\n",
    "    \n",
    "    # Llamamos a tu función de explicación individual\n",
    "    explicabilidad.explicar_prediccion_individual(explainer, X_test, posicion_en_test)\n",
    "else:\n",
    "    print(\"No se encontraron casos de fraude en el set de prueba para analizar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
