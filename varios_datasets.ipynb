{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos a comparar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Para mostrar la tabla final\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, models, dataset_name):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa una lista de modelos en un dataset.\n",
    "    Devuelve una lista de diccionarios con los resultados de cada modelo.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluando Dataset: {dataset_name} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    # Preprocesamiento\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # División de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    # Bucle para probar cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nProbando modelo: {model_name}...\")\n",
    "        \n",
    "        # Crear y entrenar el pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calcular y mostrar métricas\n",
    "        print(\"Matriz de Confusión:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "        print(f\"F1-Score (clase 'mala'): {f1:.3f}\")\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results_list.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1_score_bad_class': f1\n",
    "        })\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cargando y procesando dataset: German Credit ---\n",
      "--- Evaluando Dataset: German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusión:\n",
      "[[187  23]\n",
      " [ 42  48]]\n",
      "Balanced Accuracy: 0.712\n",
      "F1-Score (clase 'mala'): 0.596\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusión:\n",
      "[[196  14]\n",
      " [ 55  35]]\n",
      "Balanced Accuracy: 0.661\n",
      "F1-Score (clase 'mala'): 0.504\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusión:\n",
      "[[196  14]\n",
      " [ 53  37]]\n",
      "Balanced Accuracy: 0.672\n",
      "F1-Score (clase 'mala'): 0.525\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusión:\n",
      "[[158  52]\n",
      " [ 51  39]]\n",
      "Balanced Accuracy: 0.593\n",
      "F1-Score (clase 'mala'): 0.431\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Cargando y procesando dataset: Taiwan Credit Default ---\n",
      "--- Evaluando Dataset: Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusión:\n",
      "[[ 482 1509]\n",
      " [ 183 6826]]\n",
      "Balanced Accuracy: 0.608\n",
      "F1-Score (clase 'mala'): 0.890\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusión:\n",
      "[[ 771 1220]\n",
      " [ 399 6610]]\n",
      "Balanced Accuracy: 0.665\n",
      "F1-Score (clase 'mala'): 0.891\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusión:\n",
      "[[ 676 1315]\n",
      " [ 284 6725]]\n",
      "Balanced Accuracy: 0.650\n",
      "F1-Score (clase 'mala'): 0.894\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusión:\n",
      "[[ 836 1155]\n",
      " [1265 5744]]\n",
      "Balanced Accuracy: 0.620\n",
      "F1-Score (clase 'mala'): 0.826\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Cargando y procesando dataset: Credit Card Fraud ---\n",
      "--- Evaluando Dataset: Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusión:\n",
      "[[85280    15]\n",
      " [   57    91]]\n",
      "Balanced Accuracy: 0.807\n",
      "F1-Score (clase 'mala'): 0.717\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusión:\n",
      "[[85290     5]\n",
      " [   35   113]]\n",
      "Balanced Accuracy: 0.882\n",
      "F1-Score (clase 'mala'): 0.850\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusión:\n",
      "[[85292     3]\n",
      " [   59    89]]\n",
      "Balanced Accuracy: 0.801\n",
      "F1-Score (clase 'mala'): 0.742\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusión:\n",
      "[[85269    26]\n",
      " [   39   109]]\n",
      "Balanced Accuracy: 0.868\n",
      "F1-Score (clase 'mala'): 0.770\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Cargando y procesando dataset: Give Me Some Credit ---\n",
      "--- Evaluando Dataset: Give Me Some Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusión:\n",
      "[[41898    94]\n",
      " [ 2883   125]]\n",
      "Balanced Accuracy: 0.520\n",
      "F1-Score (clase 'mala'): 0.077\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusión:\n",
      "[[41555   437]\n",
      " [ 2453   555]]\n",
      "Balanced Accuracy: 0.587\n",
      "F1-Score (clase 'mala'): 0.278\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusión:\n",
      "[[41924    68]\n",
      " [ 2866   142]]\n",
      "Balanced Accuracy: 0.523\n",
      "F1-Score (clase 'mala'): 0.088\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusión:\n",
      "[[39631  2361]\n",
      " [ 2147   861]]\n",
      "Balanced Accuracy: 0.615\n",
      "F1-Score (clase 'mala'): 0.276\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- REEMPLAZA TU CELDA 4 POR ESTA ---\n",
    "\n",
    "# Primero, descarga el fichero 'cs-training.csv' de Kaggle y guárdalo en la misma carpeta que este notebook.\n",
    "\n",
    "datasets_to_test = {\n",
    "    'German Credit': {'source': 'openml', 'id': 31},\n",
    "    'Taiwan Credit Default': {'source': 'openml', 'id': 42477},\n",
    "    'Credit Card Fraud': {'source': 'openml', 'id': 1597},\n",
    "    'Give Me Some Credit': {'source': 'csv', 'path': 'cs-training.csv', 'target_col': 'SeriousDlqin2yrs'}\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        print(f\"--- Cargando y procesando dataset: {name} ---\")\n",
    "        \n",
    "        if info['source'] == 'openml':\n",
    "            # Cargar desde OpenML\n",
    "            data = fetch_openml(data_id=info['id'], as_frame=True, parser='auto')\n",
    "            X = data.data\n",
    "            y_raw = data.target if 'target' in data else data['class']\n",
    "            # Aseguramos que 'y' sea binaria (0s y 1s)\n",
    "            y = pd.Series(pd.factorize(y_raw)[0], index=y_raw.index)\n",
    "\n",
    "        elif info['source'] == 'csv':\n",
    "            # Cargar desde archivo CSV local\n",
    "            df_csv = pd.read_csv(info['path'])\n",
    "            \n",
    "            # Limpieza específica para 'Give Me Some Credit'\n",
    "            if 'Unnamed: 0' in df_csv.columns:\n",
    "                df_csv = df_csv.drop('Unnamed: 0', axis=1)\n",
    "            \n",
    "            target_column = info['target_col']\n",
    "            X = df_csv.drop(target_column, axis=1)\n",
    "            y = df_csv[target_column] # La 'y' ya es binaria en este dataset\n",
    "            \n",
    "            # Estrategia simple para manejar valores nulos (NaN)\n",
    "            X = X.fillna(X.mean())\n",
    "\n",
    "        # Una vez cargados los datos (X, y), llamamos a la función de evaluación\n",
    "        results = evaluate_models(X, y, models_to_test, name)\n",
    "        all_results.extend(results)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"🚨 ERROR: No se encontró el archivo '{info['path']}' para el dataset {name}.\")\n",
    "        print(\"Asegúrate de que está en la misma carpeta que el notebook.\")\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 No se pudo procesar el dataset {name}. Error: {e}\")\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ --- TABLA COMPARATIVA FINAL DE MODELOS --- ✅\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.800658</td>\n",
       "      <td>0.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.524823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>0.276404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.522794</td>\n",
       "      <td>0.088254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519659</td>\n",
       "      <td>0.077471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.890896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.649504</td>\n",
       "      <td>0.893747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.619704</td>\n",
       "      <td>0.825999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.607990</td>\n",
       "      <td>0.889729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "9       Credit Card Fraud        Random Forest           0.881727  \\\n",
       "11      Credit Card Fraud        Decision Tree           0.868091   \n",
       "8       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "10      Credit Card Fraud                  SVC           0.800658   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "2           German Credit                  SVC           0.672222   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "3           German Credit        Decision Tree           0.592857   \n",
       "15    Give Me Some Credit        Decision Tree           0.615006   \n",
       "13    Give Me Some Credit        Random Forest           0.587051   \n",
       "14    Give Me Some Credit                  SVC           0.522794   \n",
       "12    Give Me Some Credit  Logistic Regression           0.519659   \n",
       "5   Taiwan Credit Default        Random Forest           0.665158   \n",
       "6   Taiwan Credit Default                  SVC           0.649504   \n",
       "7   Taiwan Credit Default        Decision Tree           0.619704   \n",
       "4   Taiwan Credit Default  Logistic Regression           0.607990   \n",
       "\n",
       "    f1_score_bad_class  \n",
       "9             0.849624  \n",
       "11            0.770318  \n",
       "8             0.716535  \n",
       "10            0.741667  \n",
       "0             0.596273  \n",
       "2             0.524823  \n",
       "1             0.503597  \n",
       "3             0.430939  \n",
       "15            0.276404  \n",
       "13            0.277500  \n",
       "14            0.088254  \n",
       "12            0.077471  \n",
       "5             0.890896  \n",
       "6             0.893747  \n",
       "7             0.825999  \n",
       "4             0.889729  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"✅ --- TABLA COMPARATIVA FINAL DE MODELOS --- ✅\")\n",
    "display(final_results_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 --- RENDIMIENTO MEDIO POR MODELO (TODOS LOS DATASETS) --- 📊\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.698762</td>\n",
       "      <td>0.630404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.673914</td>\n",
       "      <td>0.575915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.661724</td>\n",
       "      <td>0.570002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.661295</td>\n",
       "      <td>0.562123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     balanced_accuracy  f1_score_bad_class\n",
       "model                                                     \n",
       "Random Forest                 0.698762            0.630404\n",
       "Decision Tree                 0.673914            0.575915\n",
       "Logistic Regression           0.661724            0.570002\n",
       "SVC                           0.661295            0.562123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 6: Calcular y mostrar el rendimiento medio de cada modelo\n",
    "print(\"📊 --- RENDIMIENTO MEDIO POR MODELO (TODOS LOS DATASETS) --- 📊\")\n",
    "\n",
    "# Agrupamos por 'model' y calculamos la media de las métricas\n",
    "average_performance = final_results_df.groupby('model')[['balanced_accuracy', 'f1_score_bad_class']].mean()\n",
    "\n",
    "# Ordenamos por la métrica que consideremos más importante para ver el ranking\n",
    "average_performance_sorted = average_performance.sort_values(by='balanced_accuracy', ascending=False)\n",
    "\n",
    "display(average_performance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISIS SENSIBLE A COSTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report # Asegurarse de que classification_report está importado\n",
    "\n",
    "def evaluate_cost_sensitive_models(X, y, models, dataset_name):\n",
    "    \"\"\"\n",
    "    Versión de la función de evaluación que entrena los modelos\n",
    "    con sensibilidad al coste y MUESTRA los resultados detallados.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluando Dataset (Sensible a Costes): {dataset_name} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    # Mismo preprocesamiento y división que antes\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nProbando modelo: {model_name} (Sensible al Coste)...\")\n",
    "        \n",
    "        # Re-inicializamos el modelo con el parámetro class_weight='balanced'\n",
    "        if model_name == 'Logistic Regression':\n",
    "            model_cs = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "        elif model_name == 'Random Forest':\n",
    "            model_cs = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "        elif model_name == 'SVC':\n",
    "            model_cs = SVC(random_state=42, class_weight='balanced')\n",
    "        elif model_name == 'Decision Tree':\n",
    "            model_cs = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model_cs)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # --- CÓDIGO AÑADIDO PARA MOSTRAR DETALLES ---\n",
    "        print(\"Matriz de Confusión:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "        print(f\"F1-Score (clase 'mala'): {f1:.3f}\")\n",
    "        print(\"Reporte de Clasificación:\")\n",
    "        # Usamos try-except por si alguna predicción no tiene ambas clases\n",
    "        try:\n",
    "            target_names = [f'Clase {i}' for i in sorted(y.unique())]\n",
    "            print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "        except:\n",
    "            print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "        # --- FIN DEL CÓDIGO AÑADIDO ---\n",
    "\n",
    "        results_list.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1_score_bad_class': f1\n",
    "        })\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluando Dataset (Sensible a Costes): German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[150  60]\n",
      " [ 21  69]]\n",
      "Balanced Accuracy: 0.740\n",
      "F1-Score (clase 'mala'): 0.630\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.88      0.71      0.79       210\n",
      "     Clase 1       0.53      0.77      0.63        90\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.71      0.74      0.71       300\n",
      "weighted avg       0.77      0.73      0.74       300\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[194  16]\n",
      " [ 61  29]]\n",
      "Balanced Accuracy: 0.623\n",
      "F1-Score (clase 'mala'): 0.430\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.76      0.92      0.83       210\n",
      "     Clase 1       0.64      0.32      0.43        90\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.70      0.62      0.63       300\n",
      "weighted avg       0.73      0.74      0.71       300\n",
      "\n",
      "\n",
      "Probando modelo: SVC (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[151  59]\n",
      " [ 24  66]]\n",
      "Balanced Accuracy: 0.726\n",
      "F1-Score (clase 'mala'): 0.614\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.86      0.72      0.78       210\n",
      "     Clase 1       0.53      0.73      0.61        90\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.70      0.73      0.70       300\n",
      "weighted avg       0.76      0.72      0.73       300\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[155  55]\n",
      " [ 50  40]]\n",
      "Balanced Accuracy: 0.591\n",
      "F1-Score (clase 'mala'): 0.432\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.76      0.74      0.75       210\n",
      "     Clase 1       0.42      0.44      0.43        90\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.59      0.59      0.59       300\n",
      "weighted avg       0.66      0.65      0.65       300\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Evaluando Dataset (Sensible a Costes): Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[1275  716]\n",
      " [2039 4970]]\n",
      "Balanced Accuracy: 0.675\n",
      "F1-Score (clase 'mala'): 0.783\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.38      0.64      0.48      1991\n",
      "     Clase 1       0.87      0.71      0.78      7009\n",
      "\n",
      "    accuracy                           0.69      9000\n",
      "   macro avg       0.63      0.67      0.63      9000\n",
      "weighted avg       0.77      0.69      0.72      9000\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[ 724 1267]\n",
      " [ 353 6656]]\n",
      "Balanced Accuracy: 0.657\n",
      "F1-Score (clase 'mala'): 0.892\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.67      0.36      0.47      1991\n",
      "     Clase 1       0.84      0.95      0.89      7009\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.76      0.66      0.68      9000\n",
      "weighted avg       0.80      0.82      0.80      9000\n",
      "\n",
      "\n",
      "Probando modelo: SVC (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[1155  836]\n",
      " [1184 5825]]\n",
      "Balanced Accuracy: 0.706\n",
      "F1-Score (clase 'mala'): 0.852\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.49      0.58      0.53      1991\n",
      "     Clase 1       0.87      0.83      0.85      7009\n",
      "\n",
      "    accuracy                           0.78      9000\n",
      "   macro avg       0.68      0.71      0.69      9000\n",
      "weighted avg       0.79      0.78      0.78      9000\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[ 782 1209]\n",
      " [1237 5772]]\n",
      "Balanced Accuracy: 0.608\n",
      "F1-Score (clase 'mala'): 0.825\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.39      0.39      0.39      1991\n",
      "     Clase 1       0.83      0.82      0.83      7009\n",
      "\n",
      "    accuracy                           0.73      9000\n",
      "   macro avg       0.61      0.61      0.61      9000\n",
      "weighted avg       0.73      0.73      0.73      9000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Evaluando Dataset (Sensible a Costes): Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[83407  1888]\n",
      " [   19   129]]\n",
      "Balanced Accuracy: 0.925\n",
      "F1-Score (clase 'mala'): 0.119\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      0.98      0.99     85295\n",
      "     Clase 1       0.06      0.87      0.12       148\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.92      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[85292     3]\n",
      " [   44   104]]\n",
      "Balanced Accuracy: 0.851\n",
      "F1-Score (clase 'mala'): 0.816\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.97      0.70      0.82       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.99      0.85      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "Probando modelo: SVC (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[85048   247]\n",
      " [   49    99]]\n",
      "Balanced Accuracy: 0.833\n",
      "F1-Score (clase 'mala'): 0.401\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.29      0.67      0.40       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.64      0.83      0.70     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[85263    32]\n",
      " [   52    96]]\n",
      "Balanced Accuracy: 0.824\n",
      "F1-Score (clase 'mala'): 0.696\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.75      0.65      0.70       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.87      0.82      0.85     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Evaluando Dataset (Sensible a Costes): Give Me Some Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[32956  9036]\n",
      " [ 1026  1982]]\n",
      "Balanced Accuracy: 0.722\n",
      "F1-Score (clase 'mala'): 0.283\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.97      0.78      0.87     41992\n",
      "     Clase 1       0.18      0.66      0.28      3008\n",
      "\n",
      "    accuracy                           0.78     45000\n",
      "   macro avg       0.57      0.72      0.58     45000\n",
      "weighted avg       0.92      0.78      0.83     45000\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[41646   346]\n",
      " [ 2547   461]]\n",
      "Balanced Accuracy: 0.573\n",
      "F1-Score (clase 'mala'): 0.242\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.94      0.99      0.97     41992\n",
      "     Clase 1       0.57      0.15      0.24      3008\n",
      "\n",
      "    accuracy                           0.94     45000\n",
      "   macro avg       0.76      0.57      0.60     45000\n",
      "weighted avg       0.92      0.94      0.92     45000\n",
      "\n",
      "\n",
      "Probando modelo: SVC (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[35832  6160]\n",
      " [ 1005  2003]]\n",
      "Balanced Accuracy: 0.760\n",
      "F1-Score (clase 'mala'): 0.359\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.97      0.85      0.91     41992\n",
      "     Clase 1       0.25      0.67      0.36      3008\n",
      "\n",
      "    accuracy                           0.84     45000\n",
      "   macro avg       0.61      0.76      0.63     45000\n",
      "weighted avg       0.92      0.84      0.87     45000\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusión:\n",
      "[[39831  2161]\n",
      " [ 2262   746]]\n",
      "Balanced Accuracy: 0.598\n",
      "F1-Score (clase 'mala'): 0.252\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.95      0.95      0.95     41992\n",
      "     Clase 1       0.26      0.25      0.25      3008\n",
      "\n",
      "    accuracy                           0.90     45000\n",
      "   macro avg       0.60      0.60      0.60     45000\n",
      "weighted avg       0.90      0.90      0.90     45000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- AÑADE ESTA OTRA CELDA ---\n",
    "\n",
    "# Ejecutamos el mismo bucle que en la celda 4, pero llamando a la nueva función\n",
    "all_results_cs = []\n",
    "\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        if info['source'] == 'openml':\n",
    "            data = fetch_openml(data_id=info['id'], as_frame=True, parser='auto')\n",
    "            X = data.data\n",
    "            y_raw = data.target if 'target' in data else data['class']\n",
    "            y = pd.Series(pd.factorize(y_raw)[0], index=y_raw.index)\n",
    "\n",
    "        elif info['source'] == 'csv':\n",
    "            df_csv = pd.read_csv(info['path'])\n",
    "            if 'Unnamed: 0' in df_csv.columns:\n",
    "                df_csv = df_csv.drop('Unnamed: 0', axis=1)\n",
    "            target_column = info['target_col']\n",
    "            X = df_csv.drop(target_column, axis=1)\n",
    "            y = df_csv[target_column]\n",
    "            X = X.fillna(X.mean())\n",
    "\n",
    "        # Llamamos a la NUEVA función de evaluación sensible al coste\n",
    "        results_cs = evaluate_cost_sensitive_models(X, y, models_to_test, name)\n",
    "        all_results_cs.extend(results_cs)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 No se pudo procesar el dataset {name}. Error: {e}\")\n",
    "\n",
    "# Creamos un DataFrame con los nuevos resultados\n",
    "final_results_cs_df = pd.DataFrame(all_results_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 --- TABLA COMPARATIVA FINAL: EVOLUCIÓN CON SENSIBILIDAD A COSTES --- 📊\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.824137</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.924743</td>\n",
       "      <td>0.119169</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.851334</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.800658</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.833012</td>\n",
       "      <td>0.400810</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.524823</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>0.276404</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.598272</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519659</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721863</td>\n",
       "      <td>0.282618</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.572509</td>\n",
       "      <td>0.241678</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.522794</td>\n",
       "      <td>0.088254</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.759598</td>\n",
       "      <td>0.358607</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.619704</td>\n",
       "      <td>0.825999</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.608140</td>\n",
       "      <td>0.825161</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.607990</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.674735</td>\n",
       "      <td>0.782985</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.890896</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.656636</td>\n",
       "      <td>0.891508</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.649504</td>\n",
       "      <td>0.893747</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.705592</td>\n",
       "      <td>0.852231</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "11      Credit Card Fraud        Decision Tree           0.868091  \\\n",
       "11      Credit Card Fraud        Decision Tree           0.824137   \n",
       "8       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "8       Credit Card Fraud  Logistic Regression           0.924743   \n",
       "9       Credit Card Fraud        Random Forest           0.881727   \n",
       "9       Credit Card Fraud        Random Forest           0.851334   \n",
       "10      Credit Card Fraud                  SVC           0.800658   \n",
       "10      Credit Card Fraud                  SVC           0.833012   \n",
       "3           German Credit        Decision Tree           0.592857   \n",
       "3           German Credit        Decision Tree           0.591270   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "1           German Credit        Random Forest           0.623016   \n",
       "2           German Credit                  SVC           0.672222   \n",
       "2           German Credit                  SVC           0.726190   \n",
       "15    Give Me Some Credit        Decision Tree           0.615006   \n",
       "15    Give Me Some Credit        Decision Tree           0.598272   \n",
       "12    Give Me Some Credit  Logistic Regression           0.519659   \n",
       "12    Give Me Some Credit  Logistic Regression           0.721863   \n",
       "13    Give Me Some Credit        Random Forest           0.587051   \n",
       "13    Give Me Some Credit        Random Forest           0.572509   \n",
       "14    Give Me Some Credit                  SVC           0.522794   \n",
       "14    Give Me Some Credit                  SVC           0.759598   \n",
       "7   Taiwan Credit Default        Decision Tree           0.619704   \n",
       "7   Taiwan Credit Default        Decision Tree           0.608140   \n",
       "4   Taiwan Credit Default  Logistic Regression           0.607990   \n",
       "4   Taiwan Credit Default  Logistic Regression           0.674735   \n",
       "5   Taiwan Credit Default        Random Forest           0.665158   \n",
       "5   Taiwan Credit Default        Random Forest           0.656636   \n",
       "6   Taiwan Credit Default                  SVC           0.649504   \n",
       "6   Taiwan Credit Default                  SVC           0.705592   \n",
       "\n",
       "    f1_score_bad_class               Tipo  \n",
       "11            0.770318       Convencional  \n",
       "11            0.695652  Sensible al Coste  \n",
       "8             0.716535       Convencional  \n",
       "8             0.119169  Sensible al Coste  \n",
       "9             0.849624       Convencional  \n",
       "9             0.815686  Sensible al Coste  \n",
       "10            0.741667       Convencional  \n",
       "10            0.400810  Sensible al Coste  \n",
       "3             0.430939       Convencional  \n",
       "3             0.432432  Sensible al Coste  \n",
       "0             0.596273       Convencional  \n",
       "0             0.630137  Sensible al Coste  \n",
       "1             0.503597       Convencional  \n",
       "1             0.429630  Sensible al Coste  \n",
       "2             0.524823       Convencional  \n",
       "2             0.613953  Sensible al Coste  \n",
       "15            0.276404       Convencional  \n",
       "15            0.252240  Sensible al Coste  \n",
       "12            0.077471       Convencional  \n",
       "12            0.282618  Sensible al Coste  \n",
       "13            0.277500       Convencional  \n",
       "13            0.241678  Sensible al Coste  \n",
       "14            0.088254       Convencional  \n",
       "14            0.358607  Sensible al Coste  \n",
       "7             0.825999       Convencional  \n",
       "7             0.825161  Sensible al Coste  \n",
       "4             0.889729       Convencional  \n",
       "4             0.782985  Sensible al Coste  \n",
       "5             0.890896       Convencional  \n",
       "5             0.891508  Sensible al Coste  \n",
       "6             0.893747       Convencional  \n",
       "6             0.852231  Sensible al Coste  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- AÑADE ESTA CELDA FINAL ---\n",
    "\n",
    "# Añadimos una columna 'Tipo' para diferenciar los resultados\n",
    "final_results_df['Tipo'] = 'Convencional'\n",
    "final_results_cs_df['Tipo'] = 'Sensible al Coste'\n",
    "\n",
    "# Unimos las dos tablas de resultados\n",
    "comparison_df = pd.concat([final_results_df, final_results_cs_df])\n",
    "\n",
    "# Mostramos la tabla final, ordenada para facilitar la comparación\n",
    "print(\"📊 --- TABLA COMPARATIVA FINAL: EVOLUCIÓN CON SENSIBILIDAD A COSTES --- 📊\")\n",
    "\n",
    "display(comparison_df.sort_values(by=['dataset', 'model', 'Tipo']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
