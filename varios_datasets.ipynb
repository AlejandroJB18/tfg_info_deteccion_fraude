{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos a comparar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# M√©tricas de evaluaci√≥n\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Para mostrar la tabla final\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, models, dataset_name):\n",
    "    \"\"\"\n",
    "    Entrena y eval√∫a una lista de modelos en un dataset.\n",
    "    Devuelve una lista de diccionarios con los resultados de cada modelo.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluando Dataset: {dataset_name} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    # Preprocesamiento\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # Divisi√≥n de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    # Bucle para probar cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nProbando modelo: {model_name}...\")\n",
    "        \n",
    "        # Crear y entrenar el pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calcular y mostrar m√©tricas\n",
    "        print(\"Matriz de Confusi√≥n:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "        print(f\"F1-Score (clase 'mala'): {f1:.3f}\")\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results_list.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1_score_bad_class': f1\n",
    "        })\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cargando y procesando dataset: German Credit ---\n",
      "--- Evaluando Dataset: German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi√≥n:\n",
      "[[187  23]\n",
      " [ 42  48]]\n",
      "Balanced Accuracy: 0.712\n",
      "F1-Score (clase 'mala'): 0.596\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi√≥n:\n",
      "[[196  14]\n",
      " [ 55  35]]\n",
      "Balanced Accuracy: 0.661\n",
      "F1-Score (clase 'mala'): 0.504\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusi√≥n:\n",
      "[[196  14]\n",
      " [ 53  37]]\n",
      "Balanced Accuracy: 0.672\n",
      "F1-Score (clase 'mala'): 0.525\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi√≥n:\n",
      "[[158  52]\n",
      " [ 51  39]]\n",
      "Balanced Accuracy: 0.593\n",
      "F1-Score (clase 'mala'): 0.431\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Cargando y procesando dataset: Taiwan Credit Default ---\n",
      "--- Evaluando Dataset: Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi√≥n:\n",
      "[[ 482 1509]\n",
      " [ 183 6826]]\n",
      "Balanced Accuracy: 0.608\n",
      "F1-Score (clase 'mala'): 0.890\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi√≥n:\n",
      "[[ 771 1220]\n",
      " [ 399 6610]]\n",
      "Balanced Accuracy: 0.665\n",
      "F1-Score (clase 'mala'): 0.891\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusi√≥n:\n",
      "[[ 676 1315]\n",
      " [ 284 6725]]\n",
      "Balanced Accuracy: 0.650\n",
      "F1-Score (clase 'mala'): 0.894\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi√≥n:\n",
      "[[ 836 1155]\n",
      " [1265 5744]]\n",
      "Balanced Accuracy: 0.620\n",
      "F1-Score (clase 'mala'): 0.826\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Cargando y procesando dataset: Credit Card Fraud ---\n",
      "--- Evaluando Dataset: Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85280    15]\n",
      " [   57    91]]\n",
      "Balanced Accuracy: 0.807\n",
      "F1-Score (clase 'mala'): 0.717\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85290     5]\n",
      " [   35   113]]\n",
      "Balanced Accuracy: 0.882\n",
      "F1-Score (clase 'mala'): 0.850\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85292     3]\n",
      " [   59    89]]\n",
      "Balanced Accuracy: 0.801\n",
      "F1-Score (clase 'mala'): 0.742\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85269    26]\n",
      " [   39   109]]\n",
      "Balanced Accuracy: 0.868\n",
      "F1-Score (clase 'mala'): 0.770\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Cargando y procesando dataset: Give Me Some Credit ---\n",
      "--- Evaluando Dataset: Give Me Some Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusi√≥n:\n",
      "[[41898    94]\n",
      " [ 2883   125]]\n",
      "Balanced Accuracy: 0.520\n",
      "F1-Score (clase 'mala'): 0.077\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusi√≥n:\n",
      "[[41555   437]\n",
      " [ 2453   555]]\n",
      "Balanced Accuracy: 0.587\n",
      "F1-Score (clase 'mala'): 0.278\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusi√≥n:\n",
      "[[41924    68]\n",
      " [ 2866   142]]\n",
      "Balanced Accuracy: 0.523\n",
      "F1-Score (clase 'mala'): 0.088\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusi√≥n:\n",
      "[[39631  2361]\n",
      " [ 2147   861]]\n",
      "Balanced Accuracy: 0.615\n",
      "F1-Score (clase 'mala'): 0.276\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- REEMPLAZA TU CELDA 4 POR ESTA ---\n",
    "\n",
    "# Primero, descarga el fichero 'cs-training.csv' de Kaggle y gu√°rdalo en la misma carpeta que este notebook.\n",
    "\n",
    "datasets_to_test = {\n",
    "    'German Credit': {'source': 'openml', 'id': 31},\n",
    "    'Taiwan Credit Default': {'source': 'openml', 'id': 42477},\n",
    "    'Credit Card Fraud': {'source': 'openml', 'id': 1597},\n",
    "    'Give Me Some Credit': {'source': 'csv', 'path': 'cs-training.csv', 'target_col': 'SeriousDlqin2yrs'}\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        print(f\"--- Cargando y procesando dataset: {name} ---\")\n",
    "        \n",
    "        if info['source'] == 'openml':\n",
    "            # Cargar desde OpenML\n",
    "            data = fetch_openml(data_id=info['id'], as_frame=True, parser='auto')\n",
    "            X = data.data\n",
    "            y_raw = data.target if 'target' in data else data['class']\n",
    "            # Aseguramos que 'y' sea binaria (0s y 1s)\n",
    "            y = pd.Series(pd.factorize(y_raw)[0], index=y_raw.index)\n",
    "\n",
    "        elif info['source'] == 'csv':\n",
    "            # Cargar desde archivo CSV local\n",
    "            df_csv = pd.read_csv(info['path'])\n",
    "            \n",
    "            # Limpieza espec√≠fica para 'Give Me Some Credit'\n",
    "            if 'Unnamed: 0' in df_csv.columns:\n",
    "                df_csv = df_csv.drop('Unnamed: 0', axis=1)\n",
    "            \n",
    "            target_column = info['target_col']\n",
    "            X = df_csv.drop(target_column, axis=1)\n",
    "            y = df_csv[target_column] # La 'y' ya es binaria en este dataset\n",
    "            \n",
    "            # Estrategia simple para manejar valores nulos (NaN)\n",
    "            X = X.fillna(X.mean())\n",
    "\n",
    "        # Una vez cargados los datos (X, y), llamamos a la funci√≥n de evaluaci√≥n\n",
    "        results = evaluate_models(X, y, models_to_test, name)\n",
    "        all_results.extend(results)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"üö® ERROR: No se encontr√≥ el archivo '{info['path']}' para el dataset {name}.\")\n",
    "        print(\"Aseg√∫rate de que est√° en la misma carpeta que el notebook.\")\n",
    "    except Exception as e:\n",
    "        print(f\"üö® No se pudo procesar el dataset {name}. Error: {e}\")\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ --- TABLA COMPARATIVA FINAL DE MODELOS --- ‚úÖ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.800658</td>\n",
       "      <td>0.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.524823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>0.276404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.522794</td>\n",
       "      <td>0.088254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519659</td>\n",
       "      <td>0.077471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.890896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.649504</td>\n",
       "      <td>0.893747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.619704</td>\n",
       "      <td>0.825999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.607990</td>\n",
       "      <td>0.889729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "9       Credit Card Fraud        Random Forest           0.881727  \\\n",
       "11      Credit Card Fraud        Decision Tree           0.868091   \n",
       "8       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "10      Credit Card Fraud                  SVC           0.800658   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "2           German Credit                  SVC           0.672222   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "3           German Credit        Decision Tree           0.592857   \n",
       "15    Give Me Some Credit        Decision Tree           0.615006   \n",
       "13    Give Me Some Credit        Random Forest           0.587051   \n",
       "14    Give Me Some Credit                  SVC           0.522794   \n",
       "12    Give Me Some Credit  Logistic Regression           0.519659   \n",
       "5   Taiwan Credit Default        Random Forest           0.665158   \n",
       "6   Taiwan Credit Default                  SVC           0.649504   \n",
       "7   Taiwan Credit Default        Decision Tree           0.619704   \n",
       "4   Taiwan Credit Default  Logistic Regression           0.607990   \n",
       "\n",
       "    f1_score_bad_class  \n",
       "9             0.849624  \n",
       "11            0.770318  \n",
       "8             0.716535  \n",
       "10            0.741667  \n",
       "0             0.596273  \n",
       "2             0.524823  \n",
       "1             0.503597  \n",
       "3             0.430939  \n",
       "15            0.276404  \n",
       "13            0.277500  \n",
       "14            0.088254  \n",
       "12            0.077471  \n",
       "5             0.890896  \n",
       "6             0.893747  \n",
       "7             0.825999  \n",
       "4             0.889729  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"‚úÖ --- TABLA COMPARATIVA FINAL DE MODELOS --- ‚úÖ\")\n",
    "display(final_results_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä --- RENDIMIENTO MEDIO POR MODELO (TODOS LOS DATASETS) --- üìä\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.698762</td>\n",
       "      <td>0.630404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.673914</td>\n",
       "      <td>0.575915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.661724</td>\n",
       "      <td>0.570002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.661295</td>\n",
       "      <td>0.562123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     balanced_accuracy  f1_score_bad_class\n",
       "model                                                     \n",
       "Random Forest                 0.698762            0.630404\n",
       "Decision Tree                 0.673914            0.575915\n",
       "Logistic Regression           0.661724            0.570002\n",
       "SVC                           0.661295            0.562123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 6: Calcular y mostrar el rendimiento medio de cada modelo\n",
    "print(\"üìä --- RENDIMIENTO MEDIO POR MODELO (TODOS LOS DATASETS) --- üìä\")\n",
    "\n",
    "# Agrupamos por 'model' y calculamos la media de las m√©tricas\n",
    "average_performance = final_results_df.groupby('model')[['balanced_accuracy', 'f1_score_bad_class']].mean()\n",
    "\n",
    "# Ordenamos por la m√©trica que consideremos m√°s importante para ver el ranking\n",
    "average_performance_sorted = average_performance.sort_values(by='balanced_accuracy', ascending=False)\n",
    "\n",
    "display(average_performance_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISIS SENSIBLE A COSTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report # Asegurarse de que classification_report est√° importado\n",
    "\n",
    "def evaluate_cost_sensitive_models(X, y, models, dataset_name):\n",
    "    \"\"\"\n",
    "    Versi√≥n de la funci√≥n de evaluaci√≥n que entrena los modelos\n",
    "    con sensibilidad al coste y MUESTRA los resultados detallados.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluando Dataset (Sensible a Costes): {dataset_name} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    # Mismo preprocesamiento y divisi√≥n que antes\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nProbando modelo: {model_name} (Sensible al Coste)...\")\n",
    "        \n",
    "        # Re-inicializamos el modelo con el par√°metro class_weight='balanced'\n",
    "        if model_name == 'Logistic Regression':\n",
    "            model_cs = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "        elif model_name == 'Random Forest':\n",
    "            model_cs = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "        elif model_name == 'SVC':\n",
    "            model_cs = SVC(random_state=42, class_weight='balanced')\n",
    "        elif model_name == 'Decision Tree':\n",
    "            model_cs = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model_cs)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # --- C√ìDIGO A√ëADIDO PARA MOSTRAR DETALLES ---\n",
    "        print(\"Matriz de Confusi√≥n:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "        print(f\"F1-Score (clase 'mala'): {f1:.3f}\")\n",
    "        print(\"Reporte de Clasificaci√≥n:\")\n",
    "        # Usamos try-except por si alguna predicci√≥n no tiene ambas clases\n",
    "        try:\n",
    "            target_names = [f'Clase {i}' for i in sorted(y.unique())]\n",
    "            print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "        except:\n",
    "            print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "        # --- FIN DEL C√ìDIGO A√ëADIDO ---\n",
    "\n",
    "        results_list.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1_score_bad_class': f1\n",
    "        })\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluando Dataset (Sensible a Costes): German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[150  60]\n",
      " [ 21  69]]\n",
      "Balanced Accuracy: 0.740\n",
      "F1-Score (clase 'mala'): 0.630\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.88      0.71      0.79       210\n",
      "     Clase 1       0.53      0.77      0.63        90\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.71      0.74      0.71       300\n",
      "weighted avg       0.77      0.73      0.74       300\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[194  16]\n",
      " [ 61  29]]\n",
      "Balanced Accuracy: 0.623\n",
      "F1-Score (clase 'mala'): 0.430\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.76      0.92      0.83       210\n",
      "     Clase 1       0.64      0.32      0.43        90\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.70      0.62      0.63       300\n",
      "weighted avg       0.73      0.74      0.71       300\n",
      "\n",
      "\n",
      "Probando modelo: SVC (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[151  59]\n",
      " [ 24  66]]\n",
      "Balanced Accuracy: 0.726\n",
      "F1-Score (clase 'mala'): 0.614\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.86      0.72      0.78       210\n",
      "     Clase 1       0.53      0.73      0.61        90\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.70      0.73      0.70       300\n",
      "weighted avg       0.76      0.72      0.73       300\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[155  55]\n",
      " [ 50  40]]\n",
      "Balanced Accuracy: 0.591\n",
      "F1-Score (clase 'mala'): 0.432\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.76      0.74      0.75       210\n",
      "     Clase 1       0.42      0.44      0.43        90\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.59      0.59      0.59       300\n",
      "weighted avg       0.66      0.65      0.65       300\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Evaluando Dataset (Sensible a Costes): Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[1275  716]\n",
      " [2039 4970]]\n",
      "Balanced Accuracy: 0.675\n",
      "F1-Score (clase 'mala'): 0.783\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.38      0.64      0.48      1991\n",
      "     Clase 1       0.87      0.71      0.78      7009\n",
      "\n",
      "    accuracy                           0.69      9000\n",
      "   macro avg       0.63      0.67      0.63      9000\n",
      "weighted avg       0.77      0.69      0.72      9000\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[ 724 1267]\n",
      " [ 353 6656]]\n",
      "Balanced Accuracy: 0.657\n",
      "F1-Score (clase 'mala'): 0.892\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.67      0.36      0.47      1991\n",
      "     Clase 1       0.84      0.95      0.89      7009\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.76      0.66      0.68      9000\n",
      "weighted avg       0.80      0.82      0.80      9000\n",
      "\n",
      "\n",
      "Probando modelo: SVC (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[1155  836]\n",
      " [1184 5825]]\n",
      "Balanced Accuracy: 0.706\n",
      "F1-Score (clase 'mala'): 0.852\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.49      0.58      0.53      1991\n",
      "     Clase 1       0.87      0.83      0.85      7009\n",
      "\n",
      "    accuracy                           0.78      9000\n",
      "   macro avg       0.68      0.71      0.69      9000\n",
      "weighted avg       0.79      0.78      0.78      9000\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[ 782 1209]\n",
      " [1237 5772]]\n",
      "Balanced Accuracy: 0.608\n",
      "F1-Score (clase 'mala'): 0.825\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.39      0.39      0.39      1991\n",
      "     Clase 1       0.83      0.82      0.83      7009\n",
      "\n",
      "    accuracy                           0.73      9000\n",
      "   macro avg       0.61      0.61      0.61      9000\n",
      "weighted avg       0.73      0.73      0.73      9000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Evaluando Dataset (Sensible a Costes): Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[83407  1888]\n",
      " [   19   129]]\n",
      "Balanced Accuracy: 0.925\n",
      "F1-Score (clase 'mala'): 0.119\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      0.98      0.99     85295\n",
      "     Clase 1       0.06      0.87      0.12       148\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.92      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85292     3]\n",
      " [   44   104]]\n",
      "Balanced Accuracy: 0.851\n",
      "F1-Score (clase 'mala'): 0.816\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.97      0.70      0.82       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.99      0.85      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "Probando modelo: SVC (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85048   247]\n",
      " [   49    99]]\n",
      "Balanced Accuracy: 0.833\n",
      "F1-Score (clase 'mala'): 0.401\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.29      0.67      0.40       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.64      0.83      0.70     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[85263    32]\n",
      " [   52    96]]\n",
      "Balanced Accuracy: 0.824\n",
      "F1-Score (clase 'mala'): 0.696\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       1.00      1.00      1.00     85295\n",
      "     Clase 1       0.75      0.65      0.70       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.87      0.82      0.85     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Evaluando Dataset (Sensible a Costes): Give Me Some Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[32956  9036]\n",
      " [ 1026  1982]]\n",
      "Balanced Accuracy: 0.722\n",
      "F1-Score (clase 'mala'): 0.283\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.97      0.78      0.87     41992\n",
      "     Clase 1       0.18      0.66      0.28      3008\n",
      "\n",
      "    accuracy                           0.78     45000\n",
      "   macro avg       0.57      0.72      0.58     45000\n",
      "weighted avg       0.92      0.78      0.83     45000\n",
      "\n",
      "\n",
      "Probando modelo: Random Forest (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[41646   346]\n",
      " [ 2547   461]]\n",
      "Balanced Accuracy: 0.573\n",
      "F1-Score (clase 'mala'): 0.242\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.94      0.99      0.97     41992\n",
      "     Clase 1       0.57      0.15      0.24      3008\n",
      "\n",
      "    accuracy                           0.94     45000\n",
      "   macro avg       0.76      0.57      0.60     45000\n",
      "weighted avg       0.92      0.94      0.92     45000\n",
      "\n",
      "\n",
      "Probando modelo: SVC (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[35832  6160]\n",
      " [ 1005  2003]]\n",
      "Balanced Accuracy: 0.760\n",
      "F1-Score (clase 'mala'): 0.359\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.97      0.85      0.91     41992\n",
      "     Clase 1       0.25      0.67      0.36      3008\n",
      "\n",
      "    accuracy                           0.84     45000\n",
      "   macro avg       0.61      0.76      0.63     45000\n",
      "weighted avg       0.92      0.84      0.87     45000\n",
      "\n",
      "\n",
      "Probando modelo: Decision Tree (Sensible al Coste)...\n",
      "Matriz de Confusi√≥n:\n",
      "[[39831  2161]\n",
      " [ 2262   746]]\n",
      "Balanced Accuracy: 0.598\n",
      "F1-Score (clase 'mala'): 0.252\n",
      "Reporte de Clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0       0.95      0.95      0.95     41992\n",
      "     Clase 1       0.26      0.25      0.25      3008\n",
      "\n",
      "    accuracy                           0.90     45000\n",
      "   macro avg       0.60      0.60      0.60     45000\n",
      "weighted avg       0.90      0.90      0.90     45000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- A√ëADE ESTA OTRA CELDA ---\n",
    "\n",
    "# Ejecutamos el mismo bucle que en la celda 4, pero llamando a la nueva funci√≥n\n",
    "all_results_cs = []\n",
    "\n",
    "for name, info in datasets_to_test.items():\n",
    "    try:\n",
    "        if info['source'] == 'openml':\n",
    "            data = fetch_openml(data_id=info['id'], as_frame=True, parser='auto')\n",
    "            X = data.data\n",
    "            y_raw = data.target if 'target' in data else data['class']\n",
    "            y = pd.Series(pd.factorize(y_raw)[0], index=y_raw.index)\n",
    "\n",
    "        elif info['source'] == 'csv':\n",
    "            df_csv = pd.read_csv(info['path'])\n",
    "            if 'Unnamed: 0' in df_csv.columns:\n",
    "                df_csv = df_csv.drop('Unnamed: 0', axis=1)\n",
    "            target_column = info['target_col']\n",
    "            X = df_csv.drop(target_column, axis=1)\n",
    "            y = df_csv[target_column]\n",
    "            X = X.fillna(X.mean())\n",
    "\n",
    "        # Llamamos a la NUEVA funci√≥n de evaluaci√≥n sensible al coste\n",
    "        results_cs = evaluate_cost_sensitive_models(X, y, models_to_test, name)\n",
    "        all_results_cs.extend(results_cs)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üö® No se pudo procesar el dataset {name}. Error: {e}\")\n",
    "\n",
    "# Creamos un DataFrame con los nuevos resultados\n",
    "final_results_cs_df = pd.DataFrame(all_results_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä --- TABLA COMPARATIVA FINAL: EVOLUCI√ìN CON SENSIBILIDAD A COSTES --- üìä\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "      <th>Tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.824137</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.924743</td>\n",
       "      <td>0.119169</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.851334</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.800658</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.833012</td>\n",
       "      <td>0.400810</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.623016</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.524823</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615006</td>\n",
       "      <td>0.276404</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.598272</td>\n",
       "      <td>0.252240</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519659</td>\n",
       "      <td>0.077471</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721863</td>\n",
       "      <td>0.282618</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.572509</td>\n",
       "      <td>0.241678</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.522794</td>\n",
       "      <td>0.088254</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Give Me Some Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.759598</td>\n",
       "      <td>0.358607</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.619704</td>\n",
       "      <td>0.825999</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.608140</td>\n",
       "      <td>0.825161</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.607990</td>\n",
       "      <td>0.889729</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.674735</td>\n",
       "      <td>0.782985</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.890896</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.656636</td>\n",
       "      <td>0.891508</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.649504</td>\n",
       "      <td>0.893747</td>\n",
       "      <td>Convencional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.705592</td>\n",
       "      <td>0.852231</td>\n",
       "      <td>Sensible al Coste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "11      Credit Card Fraud        Decision Tree           0.868091  \\\n",
       "11      Credit Card Fraud        Decision Tree           0.824137   \n",
       "8       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "8       Credit Card Fraud  Logistic Regression           0.924743   \n",
       "9       Credit Card Fraud        Random Forest           0.881727   \n",
       "9       Credit Card Fraud        Random Forest           0.851334   \n",
       "10      Credit Card Fraud                  SVC           0.800658   \n",
       "10      Credit Card Fraud                  SVC           0.833012   \n",
       "3           German Credit        Decision Tree           0.592857   \n",
       "3           German Credit        Decision Tree           0.591270   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "0           German Credit  Logistic Regression           0.740476   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "1           German Credit        Random Forest           0.623016   \n",
       "2           German Credit                  SVC           0.672222   \n",
       "2           German Credit                  SVC           0.726190   \n",
       "15    Give Me Some Credit        Decision Tree           0.615006   \n",
       "15    Give Me Some Credit        Decision Tree           0.598272   \n",
       "12    Give Me Some Credit  Logistic Regression           0.519659   \n",
       "12    Give Me Some Credit  Logistic Regression           0.721863   \n",
       "13    Give Me Some Credit        Random Forest           0.587051   \n",
       "13    Give Me Some Credit        Random Forest           0.572509   \n",
       "14    Give Me Some Credit                  SVC           0.522794   \n",
       "14    Give Me Some Credit                  SVC           0.759598   \n",
       "7   Taiwan Credit Default        Decision Tree           0.619704   \n",
       "7   Taiwan Credit Default        Decision Tree           0.608140   \n",
       "4   Taiwan Credit Default  Logistic Regression           0.607990   \n",
       "4   Taiwan Credit Default  Logistic Regression           0.674735   \n",
       "5   Taiwan Credit Default        Random Forest           0.665158   \n",
       "5   Taiwan Credit Default        Random Forest           0.656636   \n",
       "6   Taiwan Credit Default                  SVC           0.649504   \n",
       "6   Taiwan Credit Default                  SVC           0.705592   \n",
       "\n",
       "    f1_score_bad_class               Tipo  \n",
       "11            0.770318       Convencional  \n",
       "11            0.695652  Sensible al Coste  \n",
       "8             0.716535       Convencional  \n",
       "8             0.119169  Sensible al Coste  \n",
       "9             0.849624       Convencional  \n",
       "9             0.815686  Sensible al Coste  \n",
       "10            0.741667       Convencional  \n",
       "10            0.400810  Sensible al Coste  \n",
       "3             0.430939       Convencional  \n",
       "3             0.432432  Sensible al Coste  \n",
       "0             0.596273       Convencional  \n",
       "0             0.630137  Sensible al Coste  \n",
       "1             0.503597       Convencional  \n",
       "1             0.429630  Sensible al Coste  \n",
       "2             0.524823       Convencional  \n",
       "2             0.613953  Sensible al Coste  \n",
       "15            0.276404       Convencional  \n",
       "15            0.252240  Sensible al Coste  \n",
       "12            0.077471       Convencional  \n",
       "12            0.282618  Sensible al Coste  \n",
       "13            0.277500       Convencional  \n",
       "13            0.241678  Sensible al Coste  \n",
       "14            0.088254       Convencional  \n",
       "14            0.358607  Sensible al Coste  \n",
       "7             0.825999       Convencional  \n",
       "7             0.825161  Sensible al Coste  \n",
       "4             0.889729       Convencional  \n",
       "4             0.782985  Sensible al Coste  \n",
       "5             0.890896       Convencional  \n",
       "5             0.891508  Sensible al Coste  \n",
       "6             0.893747       Convencional  \n",
       "6             0.852231  Sensible al Coste  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- A√ëADE ESTA CELDA FINAL ---\n",
    "\n",
    "# A√±adimos una columna 'Tipo' para diferenciar los resultados\n",
    "final_results_df['Tipo'] = 'Convencional'\n",
    "final_results_cs_df['Tipo'] = 'Sensible al Coste'\n",
    "\n",
    "# Unimos las dos tablas de resultados\n",
    "comparison_df = pd.concat([final_results_df, final_results_cs_df])\n",
    "\n",
    "# Mostramos la tabla final, ordenada para facilitar la comparaci√≥n\n",
    "print(\"üìä --- TABLA COMPARATIVA FINAL: EVOLUCI√ìN CON SENSIBILIDAD A COSTES --- üìä\")\n",
    "\n",
    "display(comparison_df.sort_values(by=['dataset', 'model', 'Tipo']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
