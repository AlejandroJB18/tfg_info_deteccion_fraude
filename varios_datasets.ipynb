{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos a comparar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Para mostrar la tabla final\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, models, dataset_name):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa una lista de modelos en un dataset.\n",
    "    Devuelve una lista de diccionarios con los resultados de cada modelo.\n",
    "    \"\"\"\n",
    "    print(f\"--- Evaluando Dataset: {dataset_name} ---\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    # Preprocesamiento\n",
    "    categorical_features = X.select_dtypes(include=['category', 'object']).columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # División de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    # Bucle para probar cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nProbando modelo: {model_name}...\")\n",
    "        \n",
    "        # Crear y entrenar el pipeline\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calcular y mostrar métricas\n",
    "        print(\"Matriz de Confusión:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
    "        \n",
    "        print(f\"Balanced Accuracy: {bal_acc:.3f}\")\n",
    "        print(f\"F1-Score (clase 'mala'): {f1:.3f}\")\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results_list.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': model_name,\n",
    "            'balanced_accuracy': bal_acc,\n",
    "            'f1_score_bad_class': f1\n",
    "        })\n",
    "        \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluando Dataset: German Credit ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusión:\n",
      "[[187  23]\n",
      " [ 42  48]]\n",
      "Balanced Accuracy: 0.712\n",
      "F1-Score (clase 'mala'): 0.596\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusión:\n",
      "[[196  14]\n",
      " [ 55  35]]\n",
      "Balanced Accuracy: 0.661\n",
      "F1-Score (clase 'mala'): 0.504\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusión:\n",
      "[[196  14]\n",
      " [ 53  37]]\n",
      "Balanced Accuracy: 0.672\n",
      "F1-Score (clase 'mala'): 0.525\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusión:\n",
      "[[158  52]\n",
      " [ 51  39]]\n",
      "Balanced Accuracy: 0.593\n",
      "F1-Score (clase 'mala'): 0.431\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Evaluando Dataset: Taiwan Credit Default ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusión:\n",
      "[[ 482 1509]\n",
      " [ 183 6826]]\n",
      "Balanced Accuracy: 0.608\n",
      "F1-Score (clase 'mala'): 0.890\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusión:\n",
      "[[ 771 1220]\n",
      " [ 399 6610]]\n",
      "Balanced Accuracy: 0.665\n",
      "F1-Score (clase 'mala'): 0.891\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusión:\n",
      "[[ 676 1315]\n",
      " [ 284 6725]]\n",
      "Balanced Accuracy: 0.650\n",
      "F1-Score (clase 'mala'): 0.894\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusión:\n",
      "[[ 836 1155]\n",
      " [1265 5744]]\n",
      "Balanced Accuracy: 0.620\n",
      "F1-Score (clase 'mala'): 0.826\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Evaluando Dataset: Credit Card Fraud ---\n",
      "\n",
      "Probando modelo: Logistic Regression...\n",
      "Matriz de Confusión:\n",
      "[[85280    15]\n",
      " [   57    91]]\n",
      "Balanced Accuracy: 0.807\n",
      "F1-Score (clase 'mala'): 0.717\n",
      "\n",
      "Probando modelo: Random Forest...\n",
      "Matriz de Confusión:\n",
      "[[85290     5]\n",
      " [   35   113]]\n",
      "Balanced Accuracy: 0.882\n",
      "F1-Score (clase 'mala'): 0.850\n",
      "\n",
      "Probando modelo: SVC...\n",
      "Matriz de Confusión:\n",
      "[[85292     3]\n",
      " [   59    89]]\n",
      "Balanced Accuracy: 0.801\n",
      "F1-Score (clase 'mala'): 0.742\n",
      "\n",
      "Probando modelo: Decision Tree...\n",
      "Matriz de Confusión:\n",
      "[[85269    26]\n",
      " [   39   109]]\n",
      "Balanced Accuracy: 0.868\n",
      "F1-Score (clase 'mala'): 0.770\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_to_test = {\n",
    "    'German Credit': 31,\n",
    "    'Taiwan Credit Default': 42477,\n",
    "    'Credit Card Fraud': 1597\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for name, data_id in datasets_to_test.items():\n",
    "    try:\n",
    "        data = fetch_openml(data_id=data_id, as_frame=True, parser='auto')\n",
    "        X = data.data\n",
    "        y = data.target if 'target' in data else data['class']\n",
    "        y_bin = pd.Series(pd.factorize(y)[0], index=y.index)\n",
    "        \n",
    "        # Llamar a la función que evalúa TODOS los modelos\n",
    "        results = evaluate_models(X, y_bin, models_to_test, name)\n",
    "        all_results.extend(results)\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo procesar el dataset {name}. Error: {e}\")\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ --- TABLA COMPARATIVA FINAL DE MODELOS --- ✅\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.881727</td>\n",
       "      <td>0.849624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.868091</td>\n",
       "      <td>0.770318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.807345</td>\n",
       "      <td>0.716535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Credit Card Fraud</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.800658</td>\n",
       "      <td>0.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.596273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.524823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.503597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>German Credit</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.430939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.890896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.649504</td>\n",
       "      <td>0.893747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.619704</td>\n",
       "      <td>0.825999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taiwan Credit Default</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.607990</td>\n",
       "      <td>0.889729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset                model  balanced_accuracy   \n",
       "9       Credit Card Fraud        Random Forest           0.881727  \\\n",
       "11      Credit Card Fraud        Decision Tree           0.868091   \n",
       "8       Credit Card Fraud  Logistic Regression           0.807345   \n",
       "10      Credit Card Fraud                  SVC           0.800658   \n",
       "0           German Credit  Logistic Regression           0.711905   \n",
       "2           German Credit                  SVC           0.672222   \n",
       "1           German Credit        Random Forest           0.661111   \n",
       "3           German Credit        Decision Tree           0.592857   \n",
       "5   Taiwan Credit Default        Random Forest           0.665158   \n",
       "6   Taiwan Credit Default                  SVC           0.649504   \n",
       "7   Taiwan Credit Default        Decision Tree           0.619704   \n",
       "4   Taiwan Credit Default  Logistic Regression           0.607990   \n",
       "\n",
       "    f1_score_bad_class  \n",
       "9             0.849624  \n",
       "11            0.770318  \n",
       "8             0.716535  \n",
       "10            0.741667  \n",
       "0             0.596273  \n",
       "2             0.524823  \n",
       "1             0.503597  \n",
       "3             0.430939  \n",
       "5             0.890896  \n",
       "6             0.893747  \n",
       "7             0.825999  \n",
       "4             0.889729  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"✅ --- TABLA COMPARATIVA FINAL DE MODELOS --- ✅\")\n",
    "display(final_results_df.sort_values(by=['dataset', 'balanced_accuracy'], ascending=[True, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 --- RENDIMIENTO MEDIO POR MODELO (TODOS LOS DATASETS) --- 📊\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>f1_score_bad_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.735999</td>\n",
       "      <td>0.748039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.709080</td>\n",
       "      <td>0.734179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.707462</td>\n",
       "      <td>0.720079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.693551</td>\n",
       "      <td>0.675752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     balanced_accuracy  f1_score_bad_class\n",
       "model                                                     \n",
       "Random Forest                 0.735999            0.748039\n",
       "Logistic Regression           0.709080            0.734179\n",
       "SVC                           0.707462            0.720079\n",
       "Decision Tree                 0.693551            0.675752"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 6: Calcular y mostrar el rendimiento medio de cada modelo\n",
    "print(\"📊 --- RENDIMIENTO MEDIO POR MODELO (TODOS LOS DATASETS) --- 📊\")\n",
    "\n",
    "# Agrupamos por 'model' y calculamos la media de las métricas\n",
    "average_performance = final_results_df.groupby('model')[['balanced_accuracy', 'f1_score_bad_class']].mean()\n",
    "\n",
    "# Ordenamos por la métrica que consideremos más importante para ver el ranking\n",
    "average_performance_sorted = average_performance.sort_values(by='balanced_accuracy', ascending=False)\n",
    "\n",
    "display(average_performance_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
